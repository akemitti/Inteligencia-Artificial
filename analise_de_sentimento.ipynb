{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1ca6ce41",
   "metadata": {},
   "source": [
    "# 1) Extraindo os dados dos arquivos PDF\n",
    "**Objetivo:** extrair texto de PDFs (Estatística/Política Monetária mensal, Atas do COPOM, REF semestral), limpar ruído (cabeçalho/rodapé, títulos, notas, números de página), consolidar **1 linha = 1 documento** e salvar a base para etapas futuras (ex.: sentimento por documento).\n",
    "\n",
    "**Escopo desta versão:** _não_ calcula índice de sentimento — apenas prepara a base limpa e consolidada.\n",
    "\n",
    "---\n",
    "\n",
    "## Estrutura\n",
    "1. Instalação de dependências (opcional)\n",
    "2. Configuração\n",
    "3. Utilidades de limpeza (cleaners)\n",
    "4. Extração página a página (com fallbacks)\n",
    "5. Parsing por documento (data, parágrafos)\n",
    "6. Pipeline (varredura de pastas, cache, consolidação por documento)\n",
    "7. Execução (gerar CSVs) + checagens rápidas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "af753c51",
   "metadata": {
    "vscode": {
     "languageId": "bat"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.1.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython -m pip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install -q pdfplumber==0.11.0 pypdf==4.3.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "16c40a97",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## 2) Configuração\n",
    "\n",
    "from pathlib import Path\n",
    "\n",
    "# Pastas com PDFs\n",
    "ROOTS = [\n",
    "    \"data/estatisticas\",\n",
    "    \"data/atas\",\n",
    "    \"data/ref\",\n",
    "]\n",
    "\n",
    "# Anos a considerar\n",
    "YEARS = {2022, 2023, 2024, 2025}\n",
    "\n",
    "# Parâmetros\n",
    "MIN_WORDS = 8\n",
    "CACHE_DIR = \"out/pdf_paragrafos\"   # onde ficam os .pkl por doc\n",
    "REBUILD_CACHE = False              # True apenas quando mudar as regras ou na 1ª execução\n",
    "TIPOS = {\"mensal\", \"ata\", \"ref\"}   # filtros de tipo (use None para não filtrar)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b70b347b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## 3) Utilidades de limpeza (cleaners)\n",
    "\n",
    "from __future__ import annotations\n",
    "import re, unicodedata\n",
    "from typing import List, Set, Tuple, Optional\n",
    "import pandas as pd\n",
    "from pypdf import PdfReader\n",
    "\n",
    "try:\n",
    "    import pdfplumber\n",
    "except Exception:\n",
    "    pdfplumber = None\n",
    "\n",
    "try:\n",
    "    from pdfminer_high_level import extract_text as pdfminer_extract_text  # se já estava importando de pdfminer.high_level, mantenha lá\n",
    "except Exception:\n",
    "    try:\n",
    "        from pdfminer.high_level import extract_text as pdfminer_extract_text\n",
    "    except Exception:\n",
    "        pdfminer_extract_text = None\n",
    "\n",
    "# Padrões para remoção\n",
    "PAGE_RE = re.compile(r'^\\s*(p[aá]gina)\\s+\\d+(\\s+de\\s+\\d+)?\\s*$', re.I)\n",
    "ONLY_DIGITS_RE = re.compile(r'^\\s*\\d+\\s*$')\n",
    "CAPTION_RE = re.compile(r'^\\s*(figura|gr[aá]fico|tabela)\\s*\\d+[\\.:].*$', re.I)\n",
    "NOTE_PREFIX_RE = re.compile(r'^\\s*(nota[s]?|obs\\.?|observa[cç][aã]o|fonte|elabora[cç][aã]o)\\s*[:\\-–].*$', re.I)\n",
    "FOOTNOTE_MARK_RE = re.compile(r'\\[\\d+\\]')\n",
    "SUPERSCRIPTS_RE = re.compile(r'[\\u00B9\\u00B2\\u00B3\\u2070-\\u2079]+')\n",
    "STOP_AFTER_HEADINGS_RE = re.compile(r'^\\s*(refer[eê]ncias|anexos?|gloss[aá]rio)\\b.*$', re.I | re.M)\n",
    "\n",
    "HEADER_HINTS = (\n",
    "    \"banco central do brasil\",\n",
    "    \"comitê de política monetária\",\n",
    "    \"relatório de estabilidade financeira\",\n",
    "    \"ata do copom\",\n",
    "    \"relatório de estatística\",\n",
    "    \"política monetária\",\n",
    ")\n",
    "\n",
    "DOC_TYPE_CONFIG = {\n",
    "    \"ata\":    {\"stop_after\": STOP_AFTER_HEADINGS_RE},\n",
    "    \"ref\":    {\"stop_after\": STOP_AFTER_HEADINGS_RE},\n",
    "    \"mensal\": {\"stop_after\": STOP_AFTER_HEADINGS_RE},\n",
    "}\n",
    "\n",
    "def normalize_line(s: str) -> str:\n",
    "    s = unicodedata.normalize(\"NFC\", s).strip()\n",
    "    return re.sub(r'\\s+', ' ', s)\n",
    "\n",
    "def is_short_heading(line: str, max_words: int = 8) -> bool:\n",
    "    l = normalize_line(line)\n",
    "    if not l:\n",
    "        return False\n",
    "    words = l.split()\n",
    "    if len(words) > max_words:\n",
    "        return False\n",
    "    letters = [ch for ch in l if ch.isalpha()]\n",
    "    if not letters:\n",
    "        return False\n",
    "    upper_ratio = sum(ch.isupper() for ch in letters) / len(letters)\n",
    "    return upper_ratio >= 0.8\n",
    "\n",
    "def join_hyphenated(text: str) -> str:\n",
    "    return re.sub(r'(\\w+)-\\n(\\w+)', r'\\1\\2', text)\n",
    "\n",
    "def normalize_whitespace(text: str) -> str:\n",
    "    text = text.replace(\"\\r\", \"\\n\")\n",
    "    text = re.sub(r'\\n{3,}', '\\n\\n', text)         # >=3 quebras -> 2\n",
    "    text = re.sub(r'[ \\t]+', ' ', text)            # espaços múltiplos -> 1\n",
    "    text = re.sub(r'(?<!\\n)\\n(?!\\n)', ' ', text)   # quebra simples dentro de frase -> espaço\n",
    "    text = re.sub(r' {2,}', ' ', text)\n",
    "    text = re.sub(r'\\s+([,.;:!?])', r'\\1', text)\n",
    "    return re.sub(r'\\n{3,}', '\\n\\n', text).strip()\n",
    "\n",
    "def detect_repeating_edge_lines(pages_lines: List[List[str]],\n",
    "                                top_n: int = 2, bottom_n: int = 2,\n",
    "                                threshold: float = 0.5) -> Set[str]:\n",
    "    from collections import Counter\n",
    "    cand, total = Counter(), max(1, len(pages_lines))\n",
    "    for lines in pages_lines:\n",
    "        lines_norm = [normalize_line(x) for x in lines if x.strip()]\n",
    "        top = lines_norm[:top_n]\n",
    "        bottom = lines_norm[-bottom_n:] if bottom_n else []\n",
    "        for item in set(top + bottom):\n",
    "            if item:\n",
    "                cand[item] += 1\n",
    "    rep = {s for s, c in cand.items() if c / total >= threshold}\n",
    "    rep |= {s for s in cand if any(h in s.lower() for h in HEADER_HINTS)}\n",
    "    return rep\n",
    "\n",
    "def remove_edge_lines(lines: List[str], repetitive: Set[str]) -> List[str]:\n",
    "    out = []\n",
    "    for ln in lines:\n",
    "        n = normalize_line(ln)\n",
    "        if not n:\n",
    "            continue\n",
    "        if n in repetitive:\n",
    "            continue\n",
    "        if PAGE_RE.match(n) or ONLY_DIGITS_RE.match(n):\n",
    "            continue\n",
    "        out.append(ln)\n",
    "    return out\n",
    "\n",
    "def clean_page_text(raw: str, repetitive: Set[str]) -> str:\n",
    "    lines = remove_edge_lines(raw.splitlines(), repetitive)\n",
    "    kept = []\n",
    "    for ln in lines:\n",
    "        l = normalize_line(ln)\n",
    "        if not l:\n",
    "            continue\n",
    "        if is_short_heading(l):\n",
    "            continue\n",
    "        if NOTE_PREFIX_RE.match(l) or CAPTION_RE.match(l):\n",
    "            continue\n",
    "        l = FOOTNOTE_MARK_RE.sub('', l)\n",
    "        l = SUPERSCRIPTS_RE.sub('', l)\n",
    "        kept.append(l)\n",
    "    return \"\\n\".join(kept).strip()\n",
    "\n",
    "def apply_stop_after(text: str, doc_type: str) -> str:\n",
    "    pat = DOC_TYPE_CONFIG.get(doc_type, {}).get(\"stop_after\")\n",
    "    if not pat:\n",
    "        return text\n",
    "    m = pat.search(text)\n",
    "    return text[:m.start()].rstrip() if m else text\n",
    "\n",
    "def guess_doc_type(name: str, path: Optional[Path] = None) -> str:\n",
    "    \"\"\"\n",
    "    Classifica o PDF em: 'ata' (Copom), 'ref' (Relatório de Estabilidade Financeira)\n",
    "    ou 'mensal' (Estatística/Política Monetária).\n",
    "    Regras focadas nos padrões:\n",
    "      - Copom249-not20220921249.pdf  -> ata\n",
    "      - RELESTAB202204-refPub.pdf    -> ref\n",
    "    \"\"\"\n",
    "    s = (name or \"\").lower()\n",
    "    p = (str(path.parent).lower() if path else \"\")\n",
    "    hay = f\"{s} {p}\"\n",
    "\n",
    "    # --- Atas do Copom ---\n",
    "    if (\n",
    "        \"copom\" in hay or                      # Copom249-not20220921249.pdf\n",
    "        re.search(r'(^|[/_\\-\\s])ata([/_\\-\\s]|$)', hay) or  # .../atas/... ou arquivos com \"ata\"\n",
    "        \"atas\" in hay\n",
    "    ):\n",
    "        return \"ata\"\n",
    "\n",
    "    # --- Relatório de Estabilidade Financeira (REF) ---\n",
    "    if (\n",
    "        \"relestab\" in hay or                   # RELESTAB202204-refPub.pdf\n",
    "        \"refpub\" in hay or\n",
    "        re.search(r'(^|[/_\\-\\s])ref([/_\\-\\s]|$)', hay) or\n",
    "        \"estabilidade\" in hay\n",
    "    ):\n",
    "        return \"ref\"\n",
    "\n",
    "    # --- Relatório mensal de estatística/política monetária ---\n",
    "    if any(k in hay for k in [\n",
    "        \"estatistica\", \"estatísticas\", \"politica monetaria\", \"política monetária\",\n",
    "        \"credito\", \"crédito\"\n",
    "    ]):\n",
    "        return \"mensal\"\n",
    "\n",
    "    return \"mensal\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cf8b1da6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## 4) Extração página a página (com fallbacks)\n",
    "\n",
    "def extract_pages_text(path_pdf: Path) -> List[str]:\n",
    "    pages: List[str] = []\n",
    "    # 1) pdfplumber (preferido)\n",
    "    if pdfplumber is not None:\n",
    "        try:\n",
    "            with pdfplumber.open(str(path_pdf)) as pdf:\n",
    "                for page in pdf.pages:\n",
    "                    t = page.extract_text() or \"\"\n",
    "                    pages.append(t)\n",
    "        except Exception:\n",
    "            pages = []\n",
    "    # 2) pypdf (fallback)\n",
    "    if not pages:\n",
    "        try:\n",
    "            reader = PdfReader(str(path_pdf))\n",
    "            pages = [(p.extract_text() or \"\") for p in reader.pages]\n",
    "        except Exception:\n",
    "            pages = []\n",
    "    # 3) pdfminer (fallback final)\n",
    "    if (not pages or not any(x.strip() for x in pages)) and pdfminer_extract_text:\n",
    "        try:\n",
    "            txt = pdfminer_extract_text(str(path_pdf)) or \"\"\n",
    "            pages = [p for p in re.split(r'\\\\f+', txt)]\n",
    "        except Exception:\n",
    "            pages = []\n",
    "    return pages\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3060a616",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## 5) Parsing por documento (data e parágrafos)\n",
    "\n",
    "def clean_pdf_text(path_pdf: Path, doc_type: str) -> Tuple[str, Set[str], int]:\n",
    "    raw_pages = extract_pages_text(path_pdf)\n",
    "    if not raw_pages or not any(p.strip() for p in raw_pages):\n",
    "        return \"\", set(), 0\n",
    "\n",
    "    pages_lines = [p.splitlines() for p in raw_pages]\n",
    "    repetitive = detect_repeating_edge_lines(pages_lines, top_n=2, bottom_n=2, threshold=0.5)\n",
    "    cleaned_pages = [clean_page_text(p, repetitive) for p in raw_pages]\n",
    "\n",
    "    text = \"\\n\\n\".join(p for p in cleaned_pages if p.strip())\n",
    "    text = join_hyphenated(text)\n",
    "    text = normalize_whitespace(text)\n",
    "    text = apply_stop_after(text, doc_type)\n",
    "    return text, repetitive, len(raw_pages)\n",
    "\n",
    "\n",
    "def quebrar_paragrafos(txt: str, min_palavras: int = 8) -> list[str]:\n",
    "    brutos = [p.strip() for p in re.split(r\"\\n\\s*\\n\", txt) if p.strip()]\n",
    "    pars = []\n",
    "    for p in brutos:\n",
    "        p = \" \".join([l.strip() for l in p.split(\"\\n\") if l.strip()])\n",
    "        if len(p.split()) >= min_palavras:\n",
    "            pars.append(p)\n",
    "    return pars\n",
    "\n",
    "\n",
    "from datetime import datetime\n",
    "import re\n",
    "\n",
    "def _detect_date_from_name_and_path(path: Path) -> tuple[str, pd.Timestamp] | None:\n",
    "    name = path.stem\n",
    "\n",
    "    # 1) YYYY[-_.]?MM[-_.]?DD (com separadores opcionais)\n",
    "    m = re.search(r'(20\\d{2})[-_.]?([01]\\d)[-_.]?([0-3]\\d)', name)\n",
    "    if m:\n",
    "        y, mm, dd = int(m.group(1)), int(m.group(2)), int(m.group(3))\n",
    "        try:\n",
    "            dt = datetime(y, mm, dd)\n",
    "            return f\"{y}{mm:02d}\", pd.Timestamp(dt)\n",
    "        except ValueError:\n",
    "            pass\n",
    "\n",
    "    # 2) 8 dígitos contíguos começando com 20: YYYYMMDD\n",
    "    for m in re.finditer(r'(20\\d{6})', name):\n",
    "        s = m.group(1)\n",
    "        y, mm, dd = int(s[:4]), int(s[4:6]), int(s[6:8])\n",
    "        try:\n",
    "            dt = datetime(y, mm, dd)\n",
    "            return f\"{y}{mm:02d}\", pd.Timestamp(dt)\n",
    "        except ValueError:\n",
    "            continue\n",
    "\n",
    "    # 3) 6 dígitos contíguos começando com 20: YYYYMM\n",
    "    for m in re.finditer(r'(20\\d{4})', name):\n",
    "        s = m.group(1)\n",
    "        y, mm = int(s[:4]), int(s[4:6])\n",
    "        if 1 <= mm <= 12:\n",
    "            return s, pd.Timestamp(y, mm, 1)\n",
    "\n",
    "    # 4) Fallback: ano pela pasta (ex.: .../atas/2022/) + mês de 2 dígitos no nome\n",
    "    pstr = str(path.parent).lower()\n",
    "    my = re.search(r'(20\\d{2})', pstr)\n",
    "    mm = re.search(r'(?:^|[^0-9])(0[1-9]|1[0-2])(?:[^0-9]|$)', name)\n",
    "    if my and mm:\n",
    "        y = int(my.group(1)); m = int(mm.group(1))\n",
    "        return f\"{y}{m:02d}\", pd.Timestamp(y, m, 1)\n",
    "\n",
    "    return None\n",
    "\n",
    "def data_do_arquivo(path_pdf: Path) -> tuple[str, pd.Timestamp]:\n",
    "    out = _detect_date_from_name_and_path(path_pdf)\n",
    "    if out is None:\n",
    "        raise ValueError(f\"Não encontrei data no nome/pasta do arquivo: {path_pdf.name}\")\n",
    "    return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "08522f0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## 6) Pipeline — MODO DOCUMENTO (1 linha = 1 PDF)\n",
    "\n",
    "import re\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from typing import Iterable, Union\n",
    "\n",
    "# --- helpers para nome canônico ---\n",
    "TIPO_ALIAS_OUT = {\"mensal\": \"estm\", \"ata\": \"copom\", \"ref\": \"ref\"}\n",
    "\n",
    "def doc_canonico(doc_src: str) -> str:\n",
    "    \"\"\"\n",
    "    Converte 'YYYYMM_tipo' em 'YYYYMM_estm|copom|ref'\n",
    "    Ex.: 202203_ata -> 202203_copom\n",
    "    \"\"\"\n",
    "    yyyymm = doc_src[:6]\n",
    "    tipo = doc_src.rsplit(\"_\", 1)[-1].lower()\n",
    "    return f\"{yyyymm}_{TIPO_ALIAS_OUT.get(tipo, tipo)}\"\n",
    "\n",
    "# >>> pressupõe que estas funções já existem em células anteriores:\n",
    "# data_do_arquivo(path_pdf: Path) -> (yyyymm, pd.Timestamp)\n",
    "# guess_doc_type(name: str, path: Path|None) -> \"mensal\"|\"ata\"|\"ref\"\n",
    "# clean_pdf_text(path_pdf: Path, doc_type: str) -> (texto, removed, n_pages)\n",
    "\n",
    "def processar_pdf_doc(path_pdf: Path, yyyymm_override: str | None = None) -> dict:\n",
    "    # meta\n",
    "    yyyymm, dt = data_do_arquivo(path_pdf)\n",
    "    if yyyymm_override:\n",
    "        yyyymm = yyyymm_override\n",
    "    tipo = guess_doc_type(path_pdf.name, path=path_pdf)\n",
    "    doc_src = f\"{yyyymm}_{tipo}\"\n",
    "\n",
    "    # texto limpo (documento inteiro)\n",
    "    text, _removed, _n_pages = clean_pdf_text(path_pdf, tipo)\n",
    "    if not text.strip():\n",
    "        return {}  # pular doc vazio\n",
    "\n",
    "    # nome canônico (YYYYMM_estm|copom|ref)\n",
    "    doc = doc_canonico(doc_src)\n",
    "    return {\n",
    "        \"doc\": doc,\n",
    "        \"doc_src\": doc_src,\n",
    "        \"yyyymm\": yyyymm,\n",
    "        \"tipo\": tipo,\n",
    "        \"dt\": dt,\n",
    "        \"n_chars\": len(text),\n",
    "        \"n_palavras\": len(text.split()),\n",
    "        \"texto\": text,\n",
    "    }\n",
    "\n",
    "def processar_raiz_docs(raiz: Union[str, Path, Iterable[Union[str, Path]]],\n",
    "                        anos: set[int] | None = None,\n",
    "                        rebuild_cache: bool = False,\n",
    "                        cache_dir: str = \"out/pdf_docs\") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Varre 1 ou N pastas, gera diretamente df_docs (1 linha = 1 PDF).\n",
    "    Usa cache por documento (YYYYMM_tipo) em `cache_dir`.\n",
    "    \"\"\"\n",
    "    roots = [Path(raiz)] if isinstance(raiz, (str, Path)) else [Path(r) for r in raiz]\n",
    "    cache = Path(cache_dir)\n",
    "    cache.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    rows, vistos = [], set()\n",
    "\n",
    "    for root in roots:\n",
    "        for pdf in sorted(root.rglob(\"*\")):\n",
    "            if not pdf.is_file() or pdf.suffix.lower() != \".pdf\":\n",
    "                continue\n",
    "\n",
    "            name = pdf.stem\n",
    "            # datas permissivas (pegam Copom249-not20220921249.pdf)\n",
    "            m8 = re.search(r'(20\\d{6})', name)   # YYYYMMDD\n",
    "            m6 = re.search(r'(20\\d{4})', name)   # YYYYMM\n",
    "            if m8:\n",
    "                yyyymm = m8.group(0)[:6]\n",
    "            elif m6:\n",
    "                yyyymm = m6.group(0)\n",
    "            else:\n",
    "                continue\n",
    "\n",
    "            if anos is not None and int(yyyymm[:4]) not in anos:\n",
    "                continue\n",
    "\n",
    "            tipo = guess_doc_type(name, path=pdf)\n",
    "            doc_key = f\"{yyyymm}_{tipo}\"\n",
    "            if doc_key in vistos:\n",
    "                continue\n",
    "\n",
    "            pkl_path = cache / f\"{doc_key}.pkl\"\n",
    "            if (not rebuild_cache) and pkl_path.exists():\n",
    "                try:\n",
    "                    row = pd.read_pickle(pkl_path)\n",
    "                    if isinstance(row, dict) and row.get(\"texto\"):\n",
    "                        rows.append(row)\n",
    "                        vistos.add(doc_key)\n",
    "                        continue\n",
    "                except Exception:\n",
    "                    pass\n",
    "\n",
    "            row = processar_pdf_doc(pdf, yyyymm_override=yyyymm)\n",
    "            if row:\n",
    "                pd.to_pickle(row, pkl_path)\n",
    "                rows.append(row)\n",
    "                vistos.add(doc_key)\n",
    "\n",
    "    if not rows:\n",
    "        return pd.DataFrame(columns=[\"doc\",\"doc_src\",\"yyyymm\",\"tipo\",\"dt\",\"n_chars\",\"n_palavras\",\"texto\"])\n",
    "\n",
    "    df_docs = pd.DataFrame(rows).sort_values([\"dt\",\"doc\"]).reset_index(drop=True)\n",
    "    return df_docs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "96145e94",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tipo\n",
      "mensal    42\n",
      "ata       27\n",
      "Name: count, dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>doc</th>\n",
       "      <th>doc_src</th>\n",
       "      <th>yyyymm</th>\n",
       "      <th>tipo</th>\n",
       "      <th>dt</th>\n",
       "      <th>n_chars</th>\n",
       "      <th>n_palavras</th>\n",
       "      <th>texto</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>202201_estm</td>\n",
       "      <td>202201_mensal</td>\n",
       "      <td>202201</td>\n",
       "      <td>mensal</td>\n",
       "      <td>2022-01-01</td>\n",
       "      <td>9189</td>\n",
       "      <td>1464</td>\n",
       "      <td>28.01.2022\\n\\n1. Crédito ampliado ao setor não...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>202202_estm</td>\n",
       "      <td>202202_mensal</td>\n",
       "      <td>202202</td>\n",
       "      <td>mensal</td>\n",
       "      <td>2022-02-01</td>\n",
       "      <td>10180</td>\n",
       "      <td>1629</td>\n",
       "      <td>24.02.2022\\n\\n1. Crédito ampliado ao setor não...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>202202_copom</td>\n",
       "      <td>202202_ata</td>\n",
       "      <td>202202</td>\n",
       "      <td>ata</td>\n",
       "      <td>2022-02-02</td>\n",
       "      <td>12107</td>\n",
       "      <td>1902</td>\n",
       "      <td>244ª Ata da Reunião do Comitê de Política Mone...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>202203_estm</td>\n",
       "      <td>202203_mensal</td>\n",
       "      <td>202203</td>\n",
       "      <td>mensal</td>\n",
       "      <td>2022-03-01</td>\n",
       "      <td>7075</td>\n",
       "      <td>1141</td>\n",
       "      <td>28.04.2022\\n\\n1. Crédito ampliado ao setor não...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>202203_copom</td>\n",
       "      <td>202203_ata</td>\n",
       "      <td>202203</td>\n",
       "      <td>ata</td>\n",
       "      <td>2022-03-16</td>\n",
       "      <td>15310</td>\n",
       "      <td>2449</td>\n",
       "      <td>245ª Ata da Reunião do Comitê de Política Mone...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            doc        doc_src  yyyymm    tipo         dt  n_chars  \\\n",
       "0   202201_estm  202201_mensal  202201  mensal 2022-01-01     9189   \n",
       "1   202202_estm  202202_mensal  202202  mensal 2022-02-01    10180   \n",
       "2  202202_copom     202202_ata  202202     ata 2022-02-02    12107   \n",
       "3   202203_estm  202203_mensal  202203  mensal 2022-03-01     7075   \n",
       "4  202203_copom     202203_ata  202203     ata 2022-03-16    15310   \n",
       "\n",
       "   n_palavras                                              texto  \n",
       "0        1464  28.01.2022\\n\\n1. Crédito ampliado ao setor não...  \n",
       "1        1629  24.02.2022\\n\\n1. Crédito ampliado ao setor não...  \n",
       "2        1902  244ª Ata da Reunião do Comitê de Política Mone...  \n",
       "3        1141  28.04.2022\\n\\n1. Crédito ampliado ao setor não...  \n",
       "4        2449  245ª Ata da Reunião do Comitê de Política Mone...  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ## 7) Execução (gerar CSVs) + checagens\n",
    "\n",
    "df_docs = processar_raiz_docs(\n",
    "    [\"data/estatisticas\", \"data/atas\", \"data/ref\"],\n",
    "    anos={2022, 2023, 2024, 2025},\n",
    "    rebuild_cache=True,           # True só nesta rodada\n",
    "    cache_dir=\"out/pdf_docs\",\n",
    ")\n",
    "\n",
    "assert df_docs[\"doc\"].is_unique\n",
    "print(df_docs[\"tipo\"].value_counts())\n",
    "df_docs.to_csv(\"textos_bc.csv\")\n",
    "\n",
    "# Visualização rápida\n",
    "df_docs.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "154eefbf",
   "metadata": {
    "vscode": {
     "languageId": "bat"
    }
   },
   "source": [
    "\n",
    "> **Notas**\n",
    "> - PDFs com layout multi-coluna podem exigir fallback adicional (`pdftotext -layout`) ou ajustes finos.\n",
    "> - PDFs escaneados (imagem) precisam de OCR (ex.: `pytesseract` + `pdf2image`). Este pipeline não faz OCR.\n",
    "> - Se alterar regras de limpeza (regex, `MIN_WORDS`, etc.), rode com `REBUILD_CACHE = True` uma vez.\n",
    "> - A coluna `doc` já sai no formato **`YYYYMM_estm|copom|ref`** conforme o padrão decidido."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a51c7a4",
   "metadata": {},
   "source": [
    "## Instalação\n",
    "\n",
    "O que faz: instala libs para carregar modelos (transformers), datasets (datasets), métricas (sklearn) e treino (torch/accelerate)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f571019e",
   "metadata": {
    "vscode": {
     "languageId": "bat"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in /usr/local/python/3.12.1/lib/python3.12/site-packages (4.57.1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: datasets in /usr/local/python/3.12.1/lib/python3.12/site-packages (4.3.0)\n",
      "Requirement already satisfied: scikit-learn in /usr/local/python/3.12.1/lib/python3.12/site-packages (1.7.2)\n",
      "Requirement already satisfied: accelerate in /usr/local/python/3.12.1/lib/python3.12/site-packages (1.11.0)\n",
      "Requirement already satisfied: torch in /usr/local/python/3.12.1/lib/python3.12/site-packages (2.9.0)\n",
      "Requirement already satisfied: filelock in /home/codespace/.local/lib/python3.12/site-packages (from transformers) (3.13.1)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.34.0 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from transformers) (0.35.3)\n",
      "Requirement already satisfied: numpy>=1.17 in /home/codespace/.local/lib/python3.12/site-packages (from transformers) (2.3.1)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/codespace/.local/lib/python3.12/site-packages (from transformers) (25.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /home/codespace/.local/lib/python3.12/site-packages (from transformers) (6.0.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from transformers) (2024.9.11)\n",
      "Requirement already satisfied: requests in /home/codespace/.local/lib/python3.12/site-packages (from transformers) (2.32.4)\n",
      "Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from transformers) (0.22.1)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from transformers) (0.6.2)\n",
      "Requirement already satisfied: tqdm>=4.27 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from transformers) (4.67.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /home/codespace/.local/lib/python3.12/site-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (2024.6.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /home/codespace/.local/lib/python3.12/site-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (4.14.1)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (1.1.10)\n",
      "Requirement already satisfied: pyarrow>=21.0.0 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from datasets) (21.0.0)\n",
      "Requirement already satisfied: dill<0.4.1,>=0.3.0 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from datasets) (0.4.0)\n",
      "Requirement already satisfied: pandas in /home/codespace/.local/lib/python3.12/site-packages (from datasets) (2.3.1)\n",
      "Requirement already satisfied: httpx<1.0.0 in /home/codespace/.local/lib/python3.12/site-packages (from datasets) (0.28.1)\n",
      "Requirement already satisfied: xxhash in /usr/local/python/3.12.1/lib/python3.12/site-packages (from datasets) (3.6.0)\n",
      "Requirement already satisfied: multiprocess<0.70.17 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from datasets) (0.70.16)\n",
      "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from fsspec[http]<=2025.9.0,>=2023.1.0->datasets) (3.13.1)\n",
      "Requirement already satisfied: anyio in /home/codespace/.local/lib/python3.12/site-packages (from httpx<1.0.0->datasets) (4.9.0)\n",
      "Requirement already satisfied: certifi in /home/codespace/.local/lib/python3.12/site-packages (from httpx<1.0.0->datasets) (2025.7.9)\n",
      "Requirement already satisfied: httpcore==1.* in /home/codespace/.local/lib/python3.12/site-packages (from httpx<1.0.0->datasets) (1.0.9)\n",
      "Requirement already satisfied: idna in /home/codespace/.local/lib/python3.12/site-packages (from httpx<1.0.0->datasets) (3.10)\n",
      "Requirement already satisfied: h11>=0.16 in /home/codespace/.local/lib/python3.12/site-packages (from httpcore==1.*->httpx<1.0.0->datasets) (0.16.0)\n",
      "Requirement already satisfied: scipy>=1.8.0 in /home/codespace/.local/lib/python3.12/site-packages (from scikit-learn) (1.16.0)\n",
      "Requirement already satisfied: joblib>=1.2.0 in /home/codespace/.local/lib/python3.12/site-packages (from scikit-learn) (1.5.1)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /home/codespace/.local/lib/python3.12/site-packages (from scikit-learn) (3.6.0)\n",
      "Requirement already satisfied: psutil in /home/codespace/.local/lib/python3.12/site-packages (from accelerate) (7.0.0)\n",
      "Requirement already satisfied: setuptools in /home/codespace/.local/lib/python3.12/site-packages (from torch) (80.9.0)\n",
      "Requirement already satisfied: sympy>=1.13.3 in /home/codespace/.local/lib/python3.12/site-packages (from torch) (1.13.3)\n",
      "Requirement already satisfied: networkx>=2.5.1 in /home/codespace/.local/lib/python3.12/site-packages (from torch) (3.3)\n",
      "Requirement already satisfied: jinja2 in /home/codespace/.local/lib/python3.12/site-packages (from torch) (3.1.6)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.8.93 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from torch) (12.8.93)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.8.90 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from torch) (12.8.90)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.8.90 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from torch) (12.8.90)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from torch) (9.10.2.21)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.8.4.1 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from torch) (12.8.4.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.3.3.83 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from torch) (11.3.3.83)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.9.90 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from torch) (10.3.9.90)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.7.3.90 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from torch) (11.7.3.90)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.5.8.93 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from torch) (12.5.8.93)\n",
      "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from torch) (0.7.1)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.27.5 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from torch) (2.27.5)\n",
      "Requirement already satisfied: nvidia-nvshmem-cu12==3.3.20 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from torch) (3.3.20)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.8.90 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from torch) (12.8.90)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.8.93 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from torch) (12.8.93)\n",
      "Requirement already satisfied: nvidia-cufile-cu12==1.13.1.3 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from torch) (1.13.1.3)\n",
      "Requirement already satisfied: triton==3.5.0 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from torch) (3.5.0)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.9.0,>=2023.1.0->datasets) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.9.0,>=2023.1.0->datasets) (1.4.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /home/codespace/.local/lib/python3.12/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.9.0,>=2023.1.0->datasets) (25.3.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.9.0,>=2023.1.0->datasets) (1.8.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.9.0,>=2023.1.0->datasets) (6.7.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.9.0,>=2023.1.0->datasets) (0.4.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.9.0,>=2023.1.0->datasets) (1.22.0)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /home/codespace/.local/lib/python3.12/site-packages (from requests->transformers) (3.4.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/codespace/.local/lib/python3.12/site-packages (from requests->transformers) (2.5.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /home/codespace/.local/lib/python3.12/site-packages (from sympy>=1.13.3->torch) (1.3.0)\n",
      "Requirement already satisfied: sniffio>=1.1 in /home/codespace/.local/lib/python3.12/site-packages (from anyio->httpx<1.0.0->datasets) (1.3.1)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/codespace/.local/lib/python3.12/site-packages (from jinja2->torch) (3.0.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /home/codespace/.local/lib/python3.12/site-packages (from pandas->datasets) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /home/codespace/.local/lib/python3.12/site-packages (from pandas->datasets) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /home/codespace/.local/lib/python3.12/site-packages (from pandas->datasets) (2025.2)\n",
      "Requirement already satisfied: six>=1.5 in /home/codespace/.local/lib/python3.12/site-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.1.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython -m pip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install -U transformers datasets scikit-learn accelerate torch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dc11fe3",
   "metadata": {},
   "source": [
    "# 3) FinBERT-PT-BR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "751ca69d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cpu\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from transformers import (\n",
    "    AutoTokenizer, \n",
    "    BertForSequenceClassification,\n",
    "    pipeline,\n",
    ")\n",
    "\n",
    "# ——— FinBERT-PT-BR ———\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "finbert_pt_br_tokenizer = AutoTokenizer.from_pretrained(\"lucas-leme/FinBERT-PT-BR\")\n",
    "finbert_pt_br_model = BertForSequenceClassification.from_pretrained(\"lucas-leme/FinBERT-PT-BR\").to(device).eval()\n",
    "\n",
    "# Opcional / teste rápido (vai truncar textos longos — use só para frases curtas)\n",
    "finbert_pt_br_pipeline = pipeline(\n",
    "    task='text-classification',\n",
    "    model=finbert_pt_br_model,\n",
    "    tokenizer=finbert_pt_br_tokenizer,\n",
    "    device=0 if device==\"cuda\" else -1\n",
    ")\n",
    "\n",
    "# Mapa id -> rótulo (padronizado em PT-BR)\n",
    "id2label = finbert_pt_br_model.config.id2label\n",
    "def _pt_label(i: int) -> str:\n",
    "    l = str(id2label.get(i, \"\")).lower()\n",
    "    if \"pos\" in l: return \"positivo\"\n",
    "    if \"neg\" in l: return \"negativo\"\n",
    "    if \"neu\" in l: return \"neutro\"\n",
    "    if l.startswith(\"label_\"):\n",
    "        j = int(l.split(\"_\")[-1])\n",
    "        return _pt_label(j) if j in finbert_pt_br_model.config.id2label else \"neutro\"\n",
    "    return \"neutro\" if not l else l\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "898815c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "\n",
    "MAX_LEN = 512\n",
    "CHUNK_BODY = MAX_LEN - 2\n",
    "MAX_CHUNKS = 20\n",
    "\n",
    "def classify_text_finbert(texto: str) -> dict:\n",
    "    texto = (texto or \"\").strip()\n",
    "    if not texto:\n",
    "        return {\"label\":\"neutro\",\"conf\":1.0,\"p_positivo\":0.0,\"p_negativo\":0.0,\"p_neutro\":1.0}\n",
    "\n",
    "    # 1) tokenize sem especiais p/ controlar cortes\n",
    "    ids = finbert_pt_br_tokenizer.encode(texto, add_special_tokens=False)\n",
    "    if not ids:\n",
    "        return {\"label\":\"neutro\",\"conf\":1.0,\"p_positivo\":0.0,\"p_negativo\":0.0,\"p_neutro\":1.0}\n",
    "\n",
    "    # 2) corta em janelas\n",
    "    chunks = [ids[i:i+CHUNK_BODY] for i in range(0, len(ids), CHUNK_BODY)]\n",
    "    if len(chunks) > MAX_CHUNKS:\n",
    "        chunks = chunks[:MAX_CHUNKS]\n",
    "\n",
    "    # 3) para cada chunk, decodifica para TEXTO e usa o tokenizer (__call__)\n",
    "    probs_sum = None\n",
    "    for ch in chunks:\n",
    "        chunk_text = finbert_pt_br_tokenizer.decode(ch, clean_up_tokenization_spaces=True)\n",
    "        enc = finbert_pt_br_tokenizer(\n",
    "            chunk_text,\n",
    "            return_tensors=\"pt\",\n",
    "            truncation=True,\n",
    "            max_length=MAX_LEN\n",
    "        )\n",
    "        enc = {k: v.to(device) for k, v in enc.items()}\n",
    "        with torch.no_grad():\n",
    "            logits = finbert_pt_br_model(**enc).logits  # [1, C]\n",
    "            p = F.softmax(logits, dim=-1).squeeze(0).cpu()\n",
    "        probs_sum = p if probs_sum is None else (probs_sum + p)\n",
    "\n",
    "    probs = probs_sum / len(chunks)\n",
    "\n",
    "    id2label = finbert_pt_br_model.config.id2label\n",
    "    def _pt(i): \n",
    "        l = str(id2label.get(i,\"\")).lower()\n",
    "        if \"pos\" in l: return \"positivo\"\n",
    "        if \"neg\" in l: return \"negativo\"\n",
    "        if \"neu\" in l: return \"neutro\"\n",
    "        return \"neutro\" if not l else l\n",
    "\n",
    "    scores = {_pt(i): float(probs[i]) for i in range(probs.shape[-1])}\n",
    "    p_pos = scores.get(\"positivo\", 0.0)\n",
    "    p_neg = scores.get(\"negativo\", 0.0)\n",
    "    p_neu = scores.get(\"neutro\",   0.0)\n",
    "    label = max((\"positivo\",\"negativo\",\"neutro\"), key=lambda k: {\"positivo\":p_pos,\"negativo\":p_neg,\"neutro\":p_neu}[k])\n",
    "    conf = {\"positivo\":p_pos,\"negativo\":p_neg,\"neutro\":p_neu}[label]\n",
    "    return {\"label\":label, \"conf\":conf, \"p_positivo\":p_pos, \"p_negativo\":p_neg, \"p_neutro\":p_neu}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "893e5755",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total a processar: 69 | Já processados: 0\n",
      "Checkpoint: 5 novos documentos salvos...\n",
      "Checkpoint: 10 novos documentos salvos...\n",
      "Checkpoint: 15 novos documentos salvos...\n",
      "Checkpoint: 20 novos documentos salvos...\n",
      "Checkpoint: 25 novos documentos salvos...\n",
      "Checkpoint: 30 novos documentos salvos...\n",
      "Checkpoint: 35 novos documentos salvos...\n",
      "Checkpoint: 40 novos documentos salvos...\n",
      "Checkpoint: 45 novos documentos salvos...\n",
      "Checkpoint: 50 novos documentos salvos...\n",
      "Checkpoint: 55 novos documentos salvos...\n",
      "Checkpoint: 60 novos documentos salvos...\n",
      "Checkpoint: 65 novos documentos salvos...\n",
      "Finalizado: 69 novos documentos salvos.\n"
     ]
    }
   ],
   "source": [
    "# antes (no topo)\n",
    "from datetime import datetime\n",
    "from datetime import datetime, timezone\n",
    "\n",
    "\n",
    "IN_CSV  = Path(\"textos_bc.csv\")         # entrada (1 linha = 1 PDF)\n",
    "OUT_CSV = Path(\"textos_com_sentimento.csv\")  # saída (checkpoint)\n",
    "CHECKPOINT_EVERY = 5                                 # salva a cada N docs\n",
    "\n",
    "# 1) lê entrada\n",
    "if not IN_CSV.exists():\n",
    "    raise FileNotFoundError(f\"Entrada não encontrada: {IN_CSV}\")\n",
    "df_docs = pd.read_csv(IN_CSV, encoding=\"utf-8-sig\")\n",
    "\n",
    "# chave para controle de progresso\n",
    "KEY_COL = \"doc_src\" if \"doc_src\" in df_docs.columns else \"doc\"\n",
    "if KEY_COL not in df_docs.columns:\n",
    "    df_docs[KEY_COL] = df_docs[\"doc\"]\n",
    "\n",
    "# 2) carrega progresso já salvo e cria conjunto de já processados\n",
    "processed_keys = set()\n",
    "if OUT_CSV.exists():\n",
    "    try:\n",
    "        old = pd.read_csv(OUT_CSV, encoding=\"utf-8-sig\")\n",
    "        if KEY_COL in old.columns:\n",
    "            processed_keys = set(old[KEY_COL].astype(str))\n",
    "    except Exception:\n",
    "        pass\n",
    "\n",
    "print(f\"Total a processar: {len(df_docs)} | Já processados: {len(processed_keys)}\")\n",
    "\n",
    "# 3) loop linha a linha com checkpoints\n",
    "buffer = []\n",
    "written_once = OUT_CSV.exists()\n",
    "written_count = 0\n",
    "meta_cols = [c for c in [\"doc\",\"doc_src\",\"yyyymm\",\"tipo\",\"dt\",\"n_chars\",\"n_palavras\"] if c in df_docs.columns]\n",
    "\n",
    "for _, row in df_docs.iterrows():\n",
    "    key = str(row[KEY_COL])\n",
    "    if key in processed_keys:\n",
    "        continue\n",
    "\n",
    "    res = classify_text_finbert(str(row.get(\"texto\", \"\")))\n",
    "\n",
    "    out_row = {\n",
    "        KEY_COL: key,\n",
    "        \"doc\": row.get(\"doc\", key),\n",
    "        \"sent_label\": res[\"label\"],\n",
    "        \"sent_conf\":  res[\"conf\"],\n",
    "        \"sent_p_positivo\": res[\"p_positivo\"],\n",
    "        \"sent_p_negativo\": res[\"p_negativo\"],\n",
    "        \"sent_p_neutro\":   res[\"p_neutro\"],\n",
    "        \"sent_model\": \"FinBERT-PT-BR\",\n",
    "        \"processed_at\": datetime.now(timezone.utc).isoformat(timespec=\"seconds\").replace(\"+00:00\", \"Z\"),\n",
    "    }\n",
    "    for c in meta_cols:\n",
    "        out_row[c] = row.get(c, None)\n",
    "    buffer.append(out_row)\n",
    "\n",
    "    if len(buffer) >= CHECKPOINT_EVERY:\n",
    "        pd.DataFrame(buffer).to_csv(\n",
    "            OUT_CSV, mode=\"a\", header=not written_once,\n",
    "            index=False, encoding=\"utf-8-sig\", lineterminator=\"\\n\"\n",
    "        )\n",
    "        written_once = True\n",
    "        processed_keys.update([r[KEY_COL] for r in buffer])\n",
    "        written_count += len(buffer)\n",
    "        buffer = []\n",
    "        print(f\"Checkpoint: {written_count} novos documentos salvos...\")\n",
    "\n",
    "if buffer:\n",
    "    pd.DataFrame(buffer).to_csv(\n",
    "        OUT_CSV, mode=\"a\", header=not written_once,\n",
    "        index=False, encoding=\"utf-8-sig\", lineterminator=\"\\n\"\n",
    "    )\n",
    "    processed_keys.update([r[KEY_COL] for r in buffer])\n",
    "    written_count += len(buffer)\n",
    "    print(f\"Finalizado: {written_count} novos documentos salvos.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "768fa85c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>doc_src</th>\n",
       "      <th>doc</th>\n",
       "      <th>sent_label</th>\n",
       "      <th>sent_conf</th>\n",
       "      <th>sent_p_positivo</th>\n",
       "      <th>sent_p_negativo</th>\n",
       "      <th>sent_p_neutro</th>\n",
       "      <th>sent_model</th>\n",
       "      <th>processed_at</th>\n",
       "      <th>yyyymm</th>\n",
       "      <th>tipo</th>\n",
       "      <th>dt</th>\n",
       "      <th>n_chars</th>\n",
       "      <th>n_palavras</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>202201_mensal</td>\n",
       "      <td>202201_estm</td>\n",
       "      <td>positivo</td>\n",
       "      <td>0.419371</td>\n",
       "      <td>0.419371</td>\n",
       "      <td>0.283059</td>\n",
       "      <td>0.297571</td>\n",
       "      <td>FinBERT-PT-BR</td>\n",
       "      <td>2025-10-27T03:40:10Z</td>\n",
       "      <td>202201</td>\n",
       "      <td>mensal</td>\n",
       "      <td>2022-01-01</td>\n",
       "      <td>9189</td>\n",
       "      <td>1464</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>202202_mensal</td>\n",
       "      <td>202202_estm</td>\n",
       "      <td>negativo</td>\n",
       "      <td>0.387029</td>\n",
       "      <td>0.243111</td>\n",
       "      <td>0.387029</td>\n",
       "      <td>0.369860</td>\n",
       "      <td>FinBERT-PT-BR</td>\n",
       "      <td>2025-10-27T03:40:16Z</td>\n",
       "      <td>202202</td>\n",
       "      <td>mensal</td>\n",
       "      <td>2022-02-01</td>\n",
       "      <td>10180</td>\n",
       "      <td>1629</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>202202_ata</td>\n",
       "      <td>202202_copom</td>\n",
       "      <td>negativo</td>\n",
       "      <td>0.608266</td>\n",
       "      <td>0.069367</td>\n",
       "      <td>0.608266</td>\n",
       "      <td>0.322367</td>\n",
       "      <td>FinBERT-PT-BR</td>\n",
       "      <td>2025-10-27T03:40:22Z</td>\n",
       "      <td>202202</td>\n",
       "      <td>ata</td>\n",
       "      <td>2022-02-02</td>\n",
       "      <td>12107</td>\n",
       "      <td>1902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>202203_mensal</td>\n",
       "      <td>202203_estm</td>\n",
       "      <td>positivo</td>\n",
       "      <td>0.585208</td>\n",
       "      <td>0.585208</td>\n",
       "      <td>0.224158</td>\n",
       "      <td>0.190634</td>\n",
       "      <td>FinBERT-PT-BR</td>\n",
       "      <td>2025-10-27T03:40:26Z</td>\n",
       "      <td>202203</td>\n",
       "      <td>mensal</td>\n",
       "      <td>2022-03-01</td>\n",
       "      <td>7075</td>\n",
       "      <td>1141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>202203_ata</td>\n",
       "      <td>202203_copom</td>\n",
       "      <td>neutro</td>\n",
       "      <td>0.476025</td>\n",
       "      <td>0.087618</td>\n",
       "      <td>0.436357</td>\n",
       "      <td>0.476025</td>\n",
       "      <td>FinBERT-PT-BR</td>\n",
       "      <td>2025-10-27T03:40:33Z</td>\n",
       "      <td>202203</td>\n",
       "      <td>ata</td>\n",
       "      <td>2022-03-16</td>\n",
       "      <td>15310</td>\n",
       "      <td>2449</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>202507_mensal</td>\n",
       "      <td>202507_estm</td>\n",
       "      <td>negativo</td>\n",
       "      <td>0.453914</td>\n",
       "      <td>0.323659</td>\n",
       "      <td>0.453914</td>\n",
       "      <td>0.222428</td>\n",
       "      <td>FinBERT-PT-BR</td>\n",
       "      <td>2025-10-27T03:48:36Z</td>\n",
       "      <td>202507</td>\n",
       "      <td>mensal</td>\n",
       "      <td>2025-07-01</td>\n",
       "      <td>11912</td>\n",
       "      <td>2045</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>202507_ata</td>\n",
       "      <td>202507_copom</td>\n",
       "      <td>negativo</td>\n",
       "      <td>0.495445</td>\n",
       "      <td>0.078152</td>\n",
       "      <td>0.495445</td>\n",
       "      <td>0.426403</td>\n",
       "      <td>FinBERT-PT-BR</td>\n",
       "      <td>2025-10-27T03:48:45Z</td>\n",
       "      <td>202507</td>\n",
       "      <td>ata</td>\n",
       "      <td>2025-07-30</td>\n",
       "      <td>17721</td>\n",
       "      <td>2782</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>202508_mensal</td>\n",
       "      <td>202508_estm</td>\n",
       "      <td>positivo</td>\n",
       "      <td>0.397181</td>\n",
       "      <td>0.397181</td>\n",
       "      <td>0.349911</td>\n",
       "      <td>0.252908</td>\n",
       "      <td>FinBERT-PT-BR</td>\n",
       "      <td>2025-10-27T03:48:52Z</td>\n",
       "      <td>202508</td>\n",
       "      <td>mensal</td>\n",
       "      <td>2025-08-01</td>\n",
       "      <td>10879</td>\n",
       "      <td>1881</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>202509_mensal</td>\n",
       "      <td>202509_estm</td>\n",
       "      <td>positivo</td>\n",
       "      <td>0.381392</td>\n",
       "      <td>0.381392</td>\n",
       "      <td>0.293765</td>\n",
       "      <td>0.324844</td>\n",
       "      <td>FinBERT-PT-BR</td>\n",
       "      <td>2025-10-27T03:48:59Z</td>\n",
       "      <td>202509</td>\n",
       "      <td>mensal</td>\n",
       "      <td>2025-09-01</td>\n",
       "      <td>12173</td>\n",
       "      <td>2016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>202509_ata</td>\n",
       "      <td>202509_copom</td>\n",
       "      <td>neutro</td>\n",
       "      <td>0.530513</td>\n",
       "      <td>0.093673</td>\n",
       "      <td>0.375814</td>\n",
       "      <td>0.530513</td>\n",
       "      <td>FinBERT-PT-BR</td>\n",
       "      <td>2025-10-27T03:49:07Z</td>\n",
       "      <td>202509</td>\n",
       "      <td>ata</td>\n",
       "      <td>2025-09-17</td>\n",
       "      <td>17323</td>\n",
       "      <td>2716</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>69 rows × 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          doc_src           doc sent_label  sent_conf  sent_p_positivo  \\\n",
       "0   202201_mensal   202201_estm   positivo   0.419371         0.419371   \n",
       "1   202202_mensal   202202_estm   negativo   0.387029         0.243111   \n",
       "2      202202_ata  202202_copom   negativo   0.608266         0.069367   \n",
       "3   202203_mensal   202203_estm   positivo   0.585208         0.585208   \n",
       "4      202203_ata  202203_copom     neutro   0.476025         0.087618   \n",
       "..            ...           ...        ...        ...              ...   \n",
       "64  202507_mensal   202507_estm   negativo   0.453914         0.323659   \n",
       "65     202507_ata  202507_copom   negativo   0.495445         0.078152   \n",
       "66  202508_mensal   202508_estm   positivo   0.397181         0.397181   \n",
       "67  202509_mensal   202509_estm   positivo   0.381392         0.381392   \n",
       "68     202509_ata  202509_copom     neutro   0.530513         0.093673   \n",
       "\n",
       "    sent_p_negativo  sent_p_neutro     sent_model          processed_at  \\\n",
       "0          0.283059       0.297571  FinBERT-PT-BR  2025-10-27T03:40:10Z   \n",
       "1          0.387029       0.369860  FinBERT-PT-BR  2025-10-27T03:40:16Z   \n",
       "2          0.608266       0.322367  FinBERT-PT-BR  2025-10-27T03:40:22Z   \n",
       "3          0.224158       0.190634  FinBERT-PT-BR  2025-10-27T03:40:26Z   \n",
       "4          0.436357       0.476025  FinBERT-PT-BR  2025-10-27T03:40:33Z   \n",
       "..              ...            ...            ...                   ...   \n",
       "64         0.453914       0.222428  FinBERT-PT-BR  2025-10-27T03:48:36Z   \n",
       "65         0.495445       0.426403  FinBERT-PT-BR  2025-10-27T03:48:45Z   \n",
       "66         0.349911       0.252908  FinBERT-PT-BR  2025-10-27T03:48:52Z   \n",
       "67         0.293765       0.324844  FinBERT-PT-BR  2025-10-27T03:48:59Z   \n",
       "68         0.375814       0.530513  FinBERT-PT-BR  2025-10-27T03:49:07Z   \n",
       "\n",
       "    yyyymm    tipo          dt  n_chars  n_palavras  \n",
       "0   202201  mensal  2022-01-01     9189        1464  \n",
       "1   202202  mensal  2022-02-01    10180        1629  \n",
       "2   202202     ata  2022-02-02    12107        1902  \n",
       "3   202203  mensal  2022-03-01     7075        1141  \n",
       "4   202203     ata  2022-03-16    15310        2449  \n",
       "..     ...     ...         ...      ...         ...  \n",
       "64  202507  mensal  2025-07-01    11912        2045  \n",
       "65  202507     ata  2025-07-30    17721        2782  \n",
       "66  202508  mensal  2025-08-01    10879        1881  \n",
       "67  202509  mensal  2025-09-01    12173        2016  \n",
       "68  202509     ata  2025-09-17    17323        2716  \n",
       "\n",
       "[69 rows x 14 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"textos_com_sentimento.csv\")\n",
    "df.columns = [c.strip().lower() for c in df.columns]\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "050ea954",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sent_label</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>negativo</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>positivo</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>neutro</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  sent_label  count\n",
       "0   negativo     40\n",
       "1   positivo     24\n",
       "2     neutro      5"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tipo</th>\n",
       "      <th>sent_label</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ata</td>\n",
       "      <td>negativo</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ata</td>\n",
       "      <td>neutro</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>mensal</td>\n",
       "      <td>positivo</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>mensal</td>\n",
       "      <td>negativo</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>mensal</td>\n",
       "      <td>neutro</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     tipo sent_label  count\n",
       "0     ata   negativo     23\n",
       "1     ata     neutro      4\n",
       "4  mensal   positivo     24\n",
       "2  mensal   negativo     17\n",
       "3  mensal     neutro      1"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sent_label</th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>median</th>\n",
       "      <th>min</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>negativo</td>\n",
       "      <td>40</td>\n",
       "      <td>0.511221</td>\n",
       "      <td>0.509303</td>\n",
       "      <td>0.363790</td>\n",
       "      <td>0.759896</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>positivo</td>\n",
       "      <td>24</td>\n",
       "      <td>0.493318</td>\n",
       "      <td>0.482361</td>\n",
       "      <td>0.381392</td>\n",
       "      <td>0.662053</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>neutro</td>\n",
       "      <td>5</td>\n",
       "      <td>0.485584</td>\n",
       "      <td>0.480314</td>\n",
       "      <td>0.422176</td>\n",
       "      <td>0.530513</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  sent_label  count      mean    median       min       max\n",
       "0   negativo     40  0.511221  0.509303  0.363790  0.759896\n",
       "2   positivo     24  0.493318  0.482361  0.381392  0.662053\n",
       "1     neutro      5  0.485584  0.480314  0.422176  0.530513"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>yyyymm</th>\n",
       "      <th>sent_label</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>202201</td>\n",
       "      <td>positivo</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>202202</td>\n",
       "      <td>negativo</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>202203</td>\n",
       "      <td>neutro</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>202203</td>\n",
       "      <td>positivo</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>202205</td>\n",
       "      <td>negativo</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>202205</td>\n",
       "      <td>positivo</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>202206</td>\n",
       "      <td>negativo</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>202207</td>\n",
       "      <td>positivo</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>202208</td>\n",
       "      <td>negativo</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>202209</td>\n",
       "      <td>negativo</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>202209</td>\n",
       "      <td>positivo</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>202210</td>\n",
       "      <td>negativo</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>202210</td>\n",
       "      <td>positivo</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>202211</td>\n",
       "      <td>positivo</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>202212</td>\n",
       "      <td>negativo</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>202212</td>\n",
       "      <td>positivo</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>202301</td>\n",
       "      <td>positivo</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>202302</td>\n",
       "      <td>negativo</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>202303</td>\n",
       "      <td>negativo</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>202303</td>\n",
       "      <td>positivo</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>202304</td>\n",
       "      <td>positivo</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>202305</td>\n",
       "      <td>negativo</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>202305</td>\n",
       "      <td>neutro</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>202306</td>\n",
       "      <td>negativo</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>202306</td>\n",
       "      <td>neutro</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>202307</td>\n",
       "      <td>positivo</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>202308</td>\n",
       "      <td>negativo</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>202309</td>\n",
       "      <td>negativo</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>202309</td>\n",
       "      <td>positivo</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>202310</td>\n",
       "      <td>negativo</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>202311</td>\n",
       "      <td>negativo</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>202312</td>\n",
       "      <td>positivo</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>202401</td>\n",
       "      <td>positivo</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>202402</td>\n",
       "      <td>negativo</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>202403</td>\n",
       "      <td>negativo</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>202404</td>\n",
       "      <td>positivo</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>202405</td>\n",
       "      <td>negativo</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>202406</td>\n",
       "      <td>negativo</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>202406</td>\n",
       "      <td>positivo</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>202407</td>\n",
       "      <td>negativo</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>202408</td>\n",
       "      <td>negativo</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>202409</td>\n",
       "      <td>negativo</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>202409</td>\n",
       "      <td>neutro</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>202410</td>\n",
       "      <td>negativo</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>202411</td>\n",
       "      <td>negativo</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>202412</td>\n",
       "      <td>negativo</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>202501</td>\n",
       "      <td>negativo</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>202501</td>\n",
       "      <td>positivo</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>202502</td>\n",
       "      <td>negativo</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>202503</td>\n",
       "      <td>negativo</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>202503</td>\n",
       "      <td>positivo</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>202504</td>\n",
       "      <td>positivo</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>202505</td>\n",
       "      <td>negativo</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>202505</td>\n",
       "      <td>positivo</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>202506</td>\n",
       "      <td>negativo</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>202506</td>\n",
       "      <td>positivo</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>202507</td>\n",
       "      <td>negativo</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>202508</td>\n",
       "      <td>positivo</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>202509</td>\n",
       "      <td>neutro</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>202509</td>\n",
       "      <td>positivo</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    yyyymm sent_label  count\n",
       "0   202201   positivo      1\n",
       "1   202202   negativo      2\n",
       "2   202203     neutro      1\n",
       "3   202203   positivo      1\n",
       "4   202205   negativo      1\n",
       "5   202205   positivo      1\n",
       "6   202206   negativo      1\n",
       "7   202207   positivo      1\n",
       "8   202208   negativo      1\n",
       "9   202209   negativo      1\n",
       "10  202209   positivo      1\n",
       "11  202210   negativo      1\n",
       "12  202210   positivo      1\n",
       "13  202211   positivo      1\n",
       "14  202212   negativo      1\n",
       "15  202212   positivo      1\n",
       "16  202301   positivo      1\n",
       "17  202302   negativo      2\n",
       "18  202303   negativo      1\n",
       "19  202303   positivo      1\n",
       "20  202304   positivo      1\n",
       "21  202305   negativo      1\n",
       "22  202305     neutro      1\n",
       "23  202306   negativo      1\n",
       "24  202306     neutro      1\n",
       "25  202307   positivo      1\n",
       "26  202308   negativo      2\n",
       "27  202309   negativo      1\n",
       "28  202309   positivo      1\n",
       "29  202310   negativo      1\n",
       "30  202311   negativo      2\n",
       "31  202312   positivo      1\n",
       "32  202401   positivo      1\n",
       "33  202402   negativo      1\n",
       "34  202403   negativo      1\n",
       "35  202404   positivo      1\n",
       "36  202405   negativo      2\n",
       "37  202406   negativo      1\n",
       "38  202406   positivo      1\n",
       "39  202407   negativo      2\n",
       "40  202408   negativo      1\n",
       "41  202409   negativo      1\n",
       "42  202409     neutro      1\n",
       "43  202410   negativo      1\n",
       "44  202411   negativo      2\n",
       "45  202412   negativo      2\n",
       "46  202501   negativo      1\n",
       "47  202501   positivo      1\n",
       "48  202502   negativo      1\n",
       "49  202503   negativo      1\n",
       "50  202503   positivo      1\n",
       "51  202504   positivo      1\n",
       "52  202505   negativo      1\n",
       "53  202505   positivo      1\n",
       "54  202506   negativo      1\n",
       "55  202506   positivo      1\n",
       "56  202507   negativo      2\n",
       "57  202508   positivo      1\n",
       "58  202509     neutro      1\n",
       "59  202509   positivo      1"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>doc</th>\n",
       "      <th>doc_src</th>\n",
       "      <th>tipo</th>\n",
       "      <th>yyyymm</th>\n",
       "      <th>sent_label</th>\n",
       "      <th>sent_conf</th>\n",
       "      <th>snippet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>202302_estm</td>\n",
       "      <td>202302_mensal</td>\n",
       "      <td>mensal</td>\n",
       "      <td>202302</td>\n",
       "      <td>negativo</td>\n",
       "      <td>0.363790</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>202412_estm</td>\n",
       "      <td>202412_mensal</td>\n",
       "      <td>mensal</td>\n",
       "      <td>202412</td>\n",
       "      <td>negativo</td>\n",
       "      <td>0.373515</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>202509_estm</td>\n",
       "      <td>202509_mensal</td>\n",
       "      <td>mensal</td>\n",
       "      <td>202509</td>\n",
       "      <td>positivo</td>\n",
       "      <td>0.381392</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>202202_estm</td>\n",
       "      <td>202202_mensal</td>\n",
       "      <td>mensal</td>\n",
       "      <td>202202</td>\n",
       "      <td>negativo</td>\n",
       "      <td>0.387029</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>202407_estm</td>\n",
       "      <td>202407_mensal</td>\n",
       "      <td>mensal</td>\n",
       "      <td>202407</td>\n",
       "      <td>negativo</td>\n",
       "      <td>0.395016</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>202508_estm</td>\n",
       "      <td>202508_mensal</td>\n",
       "      <td>mensal</td>\n",
       "      <td>202508</td>\n",
       "      <td>positivo</td>\n",
       "      <td>0.397181</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>202406_estm</td>\n",
       "      <td>202406_mensal</td>\n",
       "      <td>mensal</td>\n",
       "      <td>202406</td>\n",
       "      <td>positivo</td>\n",
       "      <td>0.398514</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>202505_estm</td>\n",
       "      <td>202505_mensal</td>\n",
       "      <td>mensal</td>\n",
       "      <td>202505</td>\n",
       "      <td>positivo</td>\n",
       "      <td>0.405451</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>202503_estm</td>\n",
       "      <td>202503_mensal</td>\n",
       "      <td>mensal</td>\n",
       "      <td>202503</td>\n",
       "      <td>positivo</td>\n",
       "      <td>0.414476</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>202201_estm</td>\n",
       "      <td>202201_mensal</td>\n",
       "      <td>mensal</td>\n",
       "      <td>202201</td>\n",
       "      <td>positivo</td>\n",
       "      <td>0.419371</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>202409_estm</td>\n",
       "      <td>202409_mensal</td>\n",
       "      <td>mensal</td>\n",
       "      <td>202409</td>\n",
       "      <td>neutro</td>\n",
       "      <td>0.422176</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>202504_estm</td>\n",
       "      <td>202504_mensal</td>\n",
       "      <td>mensal</td>\n",
       "      <td>202504</td>\n",
       "      <td>positivo</td>\n",
       "      <td>0.423199</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            doc        doc_src    tipo  yyyymm sent_label  sent_conf snippet\n",
       "19  202302_estm  202302_mensal  mensal  202302   negativo   0.363790        \n",
       "52  202412_estm  202412_mensal  mensal  202412   negativo   0.373515        \n",
       "67  202509_estm  202509_mensal  mensal  202509   positivo   0.381392        \n",
       "1   202202_estm  202202_mensal  mensal  202202   negativo   0.387029        \n",
       "44  202407_estm  202407_mensal  mensal  202407   negativo   0.395016        \n",
       "66  202508_estm  202508_mensal  mensal  202508   positivo   0.397181        \n",
       "42  202406_estm  202406_mensal  mensal  202406   positivo   0.398514        \n",
       "60  202505_estm  202505_mensal  mensal  202505   positivo   0.405451        \n",
       "57  202503_estm  202503_mensal  mensal  202503   positivo   0.414476        \n",
       "0   202201_estm  202201_mensal  mensal  202201   positivo   0.419371        \n",
       "47  202409_estm  202409_mensal  mensal  202409     neutro   0.422176        \n",
       "59  202504_estm  202504_mensal  mensal  202504   positivo   0.423199        "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coluna 'gold_label' não encontrada; exibidas apenas visões descritivas.\n"
     ]
    }
   ],
   "source": [
    "# Normalização simples de rótulos\n",
    "def norm_lbl(x: str) -> str:\n",
    "    x = str(x).strip().lower()\n",
    "    if \"pos\" in x: return \"positivo\"\n",
    "    if \"neg\" in x: return \"negativo\"\n",
    "    if \"neu\" in x: return \"neutro\"\n",
    "    return x\n",
    "\n",
    "if \"sent_label\" in df.columns:\n",
    "    df[\"sent_label\"] = df[\"sent_label\"].map(norm_lbl)\n",
    "\n",
    "# ======= OVERVIEW (não precisa de gold) =======\n",
    "# 1) Distribuição de rótulos\n",
    "dist_labels = (\n",
    "    df[\"sent_label\"].value_counts(dropna=False)\n",
    "      .rename_axis(\"sent_label\").reset_index(name=\"count\")\n",
    ")\n",
    "display(dist_labels)\n",
    "\n",
    "# 2) Distribuição por tipo × rótulo (se houver 'tipo')\n",
    "if \"tipo\" in df.columns:\n",
    "    by_tipo = (\n",
    "        df.groupby([\"tipo\",\"sent_label\"], dropna=False).size()\n",
    "          .reset_index(name=\"count\").sort_values([\"tipo\",\"count\"], ascending=[True, False])\n",
    "    )\n",
    "    display(by_tipo)\n",
    "\n",
    "# 3) Estatísticas de confiança por rótulo\n",
    "if \"sent_conf\" in df.columns:\n",
    "    df[\"sent_conf\"] = pd.to_numeric(df[\"sent_conf\"], errors=\"coerce\").fillna(0.0)\n",
    "else:\n",
    "    df[\"sent_conf\"] = 0.0\n",
    "conf_stats = (\n",
    "    df.groupby(\"sent_label\", dropna=False)[\"sent_conf\"]\n",
    "      .agg([\"count\",\"mean\",\"median\",\"min\",\"max\"]).reset_index()\n",
    "      .sort_values(\"count\", ascending=False)\n",
    ")\n",
    "display(conf_stats)\n",
    "\n",
    "# 4) Cobertura mensal × rótulo (se houver 'yyyymm')\n",
    "if \"yyyymm\" in df.columns:\n",
    "    by_month = (\n",
    "        df.assign(yyyymm=df[\"yyyymm\"].astype(str))\n",
    "          .groupby([\"yyyymm\",\"sent_label\"], dropna=False).size().reset_index(name=\"count\")\n",
    "          .sort_values([\"yyyymm\",\"sent_label\"])\n",
    "    )\n",
    "    display(by_month)\n",
    "\n",
    "# 5) 12 documentos com menor confiança (revisão)\n",
    "if \"texto\" in df.columns:\n",
    "    df[\"snippet\"] = df[\"texto\"].astype(str).str.replace(r\"\\s+\", \" \", regex=True).str.slice(0, 220) + \"...\"\n",
    "else:\n",
    "    df[\"snippet\"] = \"\"\n",
    "cols_low = [c for c in [\"doc\",\"doc_src\",\"tipo\",\"yyyymm\",\"sent_label\",\"sent_conf\",\"snippet\"] if c in df.columns]\n",
    "display(df.sort_values(\"sent_conf\").head(12)[cols_low])\n",
    "\n",
    "# ======= MÉTRICAS (precisa de gold_label) =======\n",
    "if \"gold_label\" in df.columns:\n",
    "    from sklearn.metrics import accuracy_score, classification_report, confusion_matrix, brier_score_loss\n",
    "    df[\"gold_label\"] = df[\"gold_label\"].map(norm_lbl)\n",
    "    eval_df = df[df[\"gold_label\"].isin([\"positivo\",\"negativo\",\"neutro\"])].copy()\n",
    "\n",
    "    if not eval_df.empty:\n",
    "        y_true = eval_df[\"gold_label\"].values\n",
    "        y_pred = eval_df[\"sent_label\"].values\n",
    "\n",
    "        print(\"ACCURACY:\", accuracy_score(y_true, y_pred))\n",
    "        report = classification_report(y_true, y_pred, labels=[\"positivo\",\"negativo\",\"neutro\"], output_dict=True, zero_division=0)\n",
    "        display(pd.DataFrame(report).T)\n",
    "\n",
    "        cm = confusion_matrix(y_true, y_pred, labels=[\"positivo\",\"negativo\",\"neutro\"])\n",
    "        cm_df = pd.DataFrame(cm, index=[\"gold_pos\",\"gold_neg\",\"gold_neu\"], columns=[\"pred_pos\",\"pred_neg\",\"pred_neu\"])\n",
    "        display(cm_df)\n",
    "\n",
    "        # Brier score (se tiver probabilidades)\n",
    "        prob_cols = [\"sent_p_positivo\",\"sent_p_negativo\",\"sent_p_neutro\"]\n",
    "        if all(c in eval_df.columns for c in prob_cols):\n",
    "            P = eval_df[prob_cols].to_numpy(dtype=float)\n",
    "            classes = [\"positivo\",\"negativo\",\"neutro\"]\n",
    "            briers = []\n",
    "            for i, cls in enumerate(classes):\n",
    "                y_bin = (y_true == cls).astype(int)\n",
    "                briers.append(brier_score_loss(y_bin, P[:, i]))\n",
    "            display(pd.DataFrame({\"classe\": classes, \"brier\": briers}))\n",
    "\n",
    "        # Cobertura × acurácia por threshold de confiança\n",
    "        if \"sent_conf\" in eval_df.columns:\n",
    "            def acc_at(t):\n",
    "                sub = eval_df[eval_df[\"sent_conf\"] >= t]\n",
    "                if sub.empty: return np.nan, 0\n",
    "                return accuracy_score(sub[\"gold_label\"], sub[\"sent_label\"]), len(sub)\n",
    "            ts = np.linspace(0.0, 0.95, 20)\n",
    "            covdf = pd.DataFrame([\n",
    "                {\"threshold\": float(t),\n",
    "                 \"accuracy\": acc_at(float(t))[0],\n",
    "                 \"coverage\": acc_at(float(t))[1]/len(eval_df)}\n",
    "                for t in ts\n",
    "            ])\n",
    "            display(covdf)\n",
    "\n",
    "            # gráfico simples (1 figura, sem cores específicas)\n",
    "            import matplotlib.pyplot as plt\n",
    "            plt.figure()\n",
    "            plt.plot(covdf[\"threshold\"], covdf[\"accuracy\"], label=\"Accuracy\")\n",
    "            plt.plot(covdf[\"threshold\"], covdf[\"coverage\"], label=\"Coverage\")\n",
    "            plt.xlabel(\"Confidence threshold\")\n",
    "            plt.ylabel(\"Metric value\")\n",
    "            plt.title(\"Coverage & Accuracy vs. Confidence Threshold\")\n",
    "            plt.legend()\n",
    "            plt.show()\n",
    "    else:\n",
    "        print(\"Sem rótulos humanos válidos em 'gold_label'; métricas de acurácia não foram calculadas.\")\n",
    "else:\n",
    "    print(\"Coluna 'gold_label' não encontrada; exibidas apenas visões descritivas.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
