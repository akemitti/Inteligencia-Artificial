{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1ca6ce41",
   "metadata": {},
   "source": [
    "# 1) Extraindo os dados dos arquivos PDF\n",
    "> Seção introdutória (markdown) que anuncia a etapa de extração de textos a partir de PDFs.\n",
    "\n",
    "---\n",
    "\n",
    "## Bloco 1 — Instalações de dependências\n",
    "**O que faz:** instala bibliotecas para leitura de PDF:\n",
    "\n",
    "- pypdf — parser de PDFs (lê estrutura, páginas).\n",
    "\n",
    "- pdfminer.six — extrator de texto de PDF (converte PDF→texto).\n",
    "\n",
    "**Por quê:** garantir ambiente reprodutível com versões fixadas (evita “quebras” ao longo do tempo).\n",
    "\n",
    "**Saída:** nenhuma variável; apenas instala pacotes no ambiente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "af753c51",
   "metadata": {
    "vscode": {
     "languageId": "bat"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pdfplumber==0.11.0\n",
      "  Downloading pdfplumber-0.11.0-py3-none-any.whl.metadata (39 kB)\n",
      "Collecting regex==2024.9.11\n",
      "  Downloading regex-2024.9.11-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (40 kB)\n",
      "Collecting pdfminer.six==20231228 (from pdfplumber==0.11.0)\n",
      "  Downloading pdfminer.six-20231228-py3-none-any.whl.metadata (4.2 kB)\n",
      "Requirement already satisfied: Pillow>=9.1 in /home/codespace/.local/lib/python3.12/site-packages (from pdfplumber==0.11.0) (11.3.0)\n",
      "Collecting pypdfium2>=4.18.0 (from pdfplumber==0.11.0)\n",
      "  Downloading pypdfium2-5.0.0-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (67 kB)\n",
      "Requirement already satisfied: charset-normalizer>=2.0.0 in /home/codespace/.local/lib/python3.12/site-packages (from pdfminer.six==20231228->pdfplumber==0.11.0) (3.4.2)\n",
      "Requirement already satisfied: cryptography>=36.0.0 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from pdfminer.six==20231228->pdfplumber==0.11.0) (46.0.3)\n",
      "Requirement already satisfied: cffi>=2.0.0 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from cryptography>=36.0.0->pdfminer.six==20231228->pdfplumber==0.11.0) (2.0.0)\n",
      "Requirement already satisfied: pycparser in /home/codespace/.local/lib/python3.12/site-packages (from cffi>=2.0.0->cryptography>=36.0.0->pdfminer.six==20231228->pdfplumber==0.11.0) (2.22)\n",
      "Downloading pdfplumber-0.11.0-py3-none-any.whl (56 kB)\n",
      "Downloading regex-2024.9.11-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (797 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m797.0/797.0 kB\u001b[0m \u001b[31m24.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading pdfminer.six-20231228-py3-none-any.whl (5.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.6/5.6 MB\u001b[0m \u001b[31m46.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading pypdfium2-5.0.0-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.0/3.0 MB\u001b[0m \u001b[31m44.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: regex, pypdfium2, pdfminer.six, pdfplumber\n",
      "\u001b[2K  Attempting uninstall: regex\n",
      "\u001b[2K    Found existing installation: regex 2025.10.23\n",
      "\u001b[2K    Uninstalling regex-2025.10.23:\n",
      "\u001b[2K      Successfully uninstalled regex-2025.10.23\n",
      "\u001b[2K   \u001b[91m━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1/4\u001b[0m [pypdfium2]\u001b[33m  WARNING: The script pypdfium2 is installed in '/usr/local/python/3.12.1/bin' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001b[0m\u001b[33m\n",
      "\u001b[2K  Attempting uninstall: pdfminer.six\n",
      "\u001b[2K    Found existing installation: pdfminer.six 20240706━━━━━━━━\u001b[0m \u001b[32m1/4\u001b[0m [pypdfium2]\n",
      "\u001b[2K    Uninstalling pdfminer.six-20240706:━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1/4\u001b[0m [pypdfium2]\n",
      "\u001b[2K      Successfully uninstalled pdfminer.six-20240706━━━━━━━━━━\u001b[0m \u001b[32m1/4\u001b[0m [pypdfium2]\n",
      "\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━\u001b[0m \u001b[32m3/4\u001b[0m [pdfplumber]\u001b[33m  WARNING: The script pdfplumber is installed in '/usr/local/python/3.12.1/bin' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001b[0m\u001b[33m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4/4\u001b[0m [pdfplumber]\n",
      "\u001b[1A\u001b[2KSuccessfully installed pdfminer.six-20231228 pdfplumber-0.11.0 pypdfium2-5.0.0 regex-2024.9.11\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.1.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython -m pip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install pdfplumber==0.11.0 regex==2024.9.11"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34a437e6",
   "metadata": {},
   "source": [
    "## Bloco 2 — Varredura e cache de parágrafos por pasta/ano\n",
    "\n",
    "**O que faz:** percorre a **raiz** com PDFs, filtra por **anos** desejados, extrai parágrafos de cada documento (via `processar_pdf`) e salva/recupera **cache** em `*.pkl` (arquivo binário do pandas) para acelerar novas execuções.\n",
    "\n",
    "**Parâmetros (principais):**\n",
    "\n",
    "* `raiz` (caminho da pasta): diretório onde estão os PDFs.\n",
    "* `min_palavras` (limiar de qualidade): descarta/funde parágrafos muito curtos.\n",
    "* `anos` (filtro temporal): limita os PDFs pelos anos no nome do arquivo (padrão `{2022, 2023, 2024, 2025}`).\n",
    "* `cache_dir` (cache em disco): pasta dos `*.pkl`.\n",
    "* `rebuild_cache` (reprocessar?): se `True`, ignora cache e reconstrói.\n",
    "\n",
    "**Conceitos rápidos:**\n",
    "\n",
    "* **Cache**: armazenamento intermediário de resultados para evitar reprocessar tudo a cada execução.\n",
    "* **YYYYMM**: carimbo de ano+mês (ex.: `202312`).\n",
    "\n",
    "**Saída:** `DataFrame` com colunas `[\"doc\",\"dt\",\"pid\",\"texto\",\"n_palavras\"]`, ordenado.\n",
    "\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d3537a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "import re, unicodedata, warnings\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "from typing import List, Set, Tuple, Optional\n",
    "import pandas as pd\n",
    "from pypdf import PdfReader\n",
    "\n",
    "# pdfplumber (preferencial)\n",
    "try:\n",
    "    import pdfplumber\n",
    "except Exception:\n",
    "    pdfplumber = None\n",
    "\n",
    "# pdfminer (fallback)\n",
    "try:\n",
    "    from pdfminer.high_level import extract_text as pdfminer_extract_text\n",
    "except Exception:\n",
    "    pdfminer_extract_text = None\n",
    "\n",
    "# ------------------ REGEX & HEURÍSTICAS ------------------\n",
    "\n",
    "PAGE_RE = re.compile(r'^\\s*(p[aá]gina)\\s+\\d+(\\s+de\\s+\\d+)?\\s*$', re.I)\n",
    "ONLY_DIGITS_RE = re.compile(r'^\\s*\\d+\\s*$')\n",
    "CAPTION_RE = re.compile(r'^\\s*(figura|gr[aá]fico|tabela)\\s*\\d+[\\.:].*$', re.I)\n",
    "NOTE_PREFIX_RE = re.compile(r'^\\s*(nota[s]?|obs\\.?|observa[cç][aã]o|fonte|elabora[cç][aã]o)\\s*[:\\-–].*$', re.I)\n",
    "FOOTNOTE_MARK_RE = re.compile(r'\\[\\d+\\]')                  # [1], [23], ...\n",
    "SUPERSCRIPTS_RE = re.compile(r'[\\u00B9\\u00B2\\u00B3\\u2070-\\u2079]+')  # ¹²³⁴…\n",
    "STOP_AFTER_HEADINGS_RE = re.compile(r'^\\s*(refer[eê]ncias|anexos?|gloss[aá]rio)\\b.*$', re.I | re.M)\n",
    "\n",
    "HEADER_HINTS = (\n",
    "    \"banco central do brasil\",\n",
    "    \"comitê de política monetária\",\n",
    "    \"relatório de estabilidade financeira\",\n",
    "    \"ata do copom\",\n",
    "    \"relatório de estatística\",\n",
    "    \"política monetária\",\n",
    ")\n",
    "\n",
    "DOC_TYPE_CONFIG = {\n",
    "    \"ata\":    {\"stop_after\": STOP_AFTER_HEADINGS_RE},\n",
    "    \"ref\":    {\"stop_after\": STOP_AFTER_HEADINGS_RE},\n",
    "    \"mensal\": {\"stop_after\": STOP_AFTER_HEADINGS_RE},\n",
    "}\n",
    "\n",
    "def normalize_line(s: str) -> str:\n",
    "    s = unicodedata.normalize(\"NFC\", s).strip()\n",
    "    s = re.sub(r'\\s+', ' ', s)\n",
    "    return s\n",
    "\n",
    "def is_short_heading(line: str, max_words: int = 8) -> bool:\n",
    "    l = normalize_line(line)\n",
    "    if not l:\n",
    "        return False\n",
    "    words = l.split()\n",
    "    if len(words) > max_words:\n",
    "        return False\n",
    "    letters = [ch for ch in l if ch.isalpha()]\n",
    "    if not letters:\n",
    "        return False\n",
    "    upper_ratio = sum(ch.isupper() for ch in letters) / len(letters)\n",
    "    return upper_ratio >= 0.8\n",
    "\n",
    "def join_hyphenated(text: str) -> str:\n",
    "    # junta palavra-\\nseguinte -> palavraseguinte\n",
    "    return re.sub(r'(\\w+)-\\n(\\w+)', r'\\1\\2', text)\n",
    "\n",
    "def normalize_whitespace(text: str) -> str:\n",
    "    text = text.replace(\"\\r\", \"\\n\")\n",
    "    text = re.sub(r'\\n{3,}', '\\n\\n', text)\n",
    "    text = re.sub(r'[ \\t]+', ' ', text)\n",
    "    text = re.sub(r'(?<!\\n)\\n(?!\\n)', ' ', text)  # quebra simples -> espaço\n",
    "    text = re.sub(r' {2,}', ' ', text)\n",
    "    text = re.sub(r'\\s+([,.;:!?])', r'\\1', text)\n",
    "    text = re.sub(r'\\n{3,}', '\\n\\n', text).strip()\n",
    "    return text\n",
    "\n",
    "def detect_repeating_edge_lines(pages_lines: List[List[str]],\n",
    "                                top_n: int = 2, bottom_n: int = 2,\n",
    "                                threshold: float = 0.5) -> Set[str]:\n",
    "    from collections import Counter\n",
    "    cand = Counter()\n",
    "    total = max(1, len(pages_lines))\n",
    "    for lines in pages_lines:\n",
    "        lines_norm = [normalize_line(x) for x in lines if x.strip()]\n",
    "        top = lines_norm[:top_n]\n",
    "        bottom = lines_norm[-bottom_n:] if bottom_n else []\n",
    "        for item in set(top + bottom):\n",
    "            if item:\n",
    "                cand[item] += 1\n",
    "    rep = {s for s, c in cand.items() if c / total >= threshold}\n",
    "    rep |= {s for s in cand if any(h in s.lower() for h in HEADER_HINTS)}\n",
    "    return rep\n",
    "\n",
    "def remove_edge_lines(lines: List[str], repetitive: Set[str]) -> List[str]:\n",
    "    out = []\n",
    "    for ln in lines:\n",
    "        n = normalize_line(ln)\n",
    "        if not n:\n",
    "            continue\n",
    "        if n in repetitive:\n",
    "            continue\n",
    "        if PAGE_RE.match(n) or ONLY_DIGITS_RE.match(n):\n",
    "            continue\n",
    "        out.append(ln)\n",
    "    return out\n",
    "\n",
    "def clean_page_text(raw: str, repetitive: Set[str]) -> str:\n",
    "    lines = raw.splitlines()\n",
    "    lines = remove_edge_lines(lines, repetitive)\n",
    "\n",
    "    kept = []\n",
    "    for ln in lines:\n",
    "        l = normalize_line(ln)\n",
    "        if not l:\n",
    "            continue\n",
    "        if is_short_heading(l):\n",
    "            continue\n",
    "        if NOTE_PREFIX_RE.match(l) or CAPTION_RE.match(l):\n",
    "            continue\n",
    "        l = FOOTNOTE_MARK_RE.sub('', l)\n",
    "        l = SUPERSCRIPTS_RE.sub('', l)\n",
    "        kept.append(l)\n",
    "    return \"\\n\".join(kept).strip()\n",
    "\n",
    "def apply_stop_after(text: str, doc_type: str) -> str:\n",
    "    pat = DOC_TYPE_CONFIG.get(doc_type, {}).get(\"stop_after\")\n",
    "    if not pat:\n",
    "        return text\n",
    "    m = pat.search(text)\n",
    "    return text[:m.start()].rstrip() if m else text\n",
    "\n",
    "def guess_doc_type(name: str) -> str:\n",
    "    s = name.lower()\n",
    "    if \"ata\" in s and \"copom\" in s: return \"ata\"\n",
    "    if \"estabilidade\" in s or \"ref\" in s: return \"ref\"\n",
    "    return \"mensal\"  # Relatório de estatística e política monetária\n",
    "\n",
    "# ------------------ EXTRAÇÃO (página a página) ------------------\n",
    "\n",
    "def extract_pages_text(path_pdf: Path) -> List[str]:\n",
    "    pages: List[str] = []\n",
    "    # 1) pdfplumber (preferido: ciente de layout)\n",
    "    if pdfplumber is not None:\n",
    "        try:\n",
    "            with pdfplumber.open(str(path_pdf)) as pdf:\n",
    "                for page in pdf.pages:\n",
    "                    t = page.extract_text() or \"\"\n",
    "                    pages.append(t)\n",
    "        except Exception:\n",
    "            pages = []\n",
    "    # 2) pypdf (fallback)\n",
    "    if not pages:\n",
    "        try:\n",
    "            reader = PdfReader(str(path_pdf))\n",
    "            pages = [(p.extract_text() or \"\") for p in reader.pages]\n",
    "        except Exception:\n",
    "            pages = []\n",
    "    # 3) pdfminer (fallback final)\n",
    "    if (not pages or not any(x.strip() for x in pages)) and pdfminer_extract_text:\n",
    "        try:\n",
    "            txt = pdfminer_extract_text(str(path_pdf)) or \"\"\n",
    "            # pdfminer separa páginas por \\f\n",
    "            pages = [p for p in re.split(r'\\f+', txt)]\n",
    "        except Exception:\n",
    "            pages = []\n",
    "    return pages\n",
    "\n",
    "def clean_pdf_text(path_pdf: Path, doc_type: str) -> Tuple[str, Set[str], int]:\n",
    "    raw_pages = extract_pages_text(path_pdf)\n",
    "    if not raw_pages or not any(p.strip() for p in raw_pages):\n",
    "        return \"\", set(), 0\n",
    "\n",
    "    pages_lines = [p.splitlines() for p in raw_pages]\n",
    "    repetitive = detect_repeating_edge_lines(pages_lines, top_n=2, bottom_n=2, threshold=0.5)\n",
    "    cleaned_pages = [clean_page_text(p, repetitive) for p in raw_pages]\n",
    "    text = \"\\n\\n\".join(p for p in cleaned_pages if p.strip())\n",
    "\n",
    "    text = join_hyphenated(text)\n",
    "    text = normalize_whitespace(text)\n",
    "    text = apply_stop_after(text, doc_type)\n",
    "    return text, repetitive, len(raw_pages)\n",
    "\n",
    "# ------------------ PARÁGRAFOS E DATA ------------------\n",
    "\n",
    "def quebrar_paragrafos(txt: str, min_palavras: int = 8) -> list[str]:\n",
    "    brutos = [p.strip() for p in re.split(r\"\\n\\s*\\n\", txt) if p.strip()]\n",
    "    pars = []\n",
    "    for p in brutos:\n",
    "        p = \" \".join([l.strip() for l in p.split(\"\\n\") if l.strip()])\n",
    "        if len(p.split()) >= min_palavras:\n",
    "            pars.append(p)\n",
    "    return pars\n",
    "\n",
    "def data_do_arquivo(path_pdf: Path) -> tuple[str, pd.Timestamp]:\n",
    "    \"\"\"\n",
    "    Detecta 202201 (YYYYMM) ou 20220131 (YYYYMMDD) em qualquer lugar do nome.\n",
    "    Retorna:\n",
    "      - yyyymm (sempre 6 dígitos)\n",
    "      - dt (Timestamp; se tiver dia usa-o, senão 1º dia do mês)\n",
    "    \"\"\"\n",
    "    name = path_pdf.stem\n",
    "    m8 = re.search(r'(?<!\\d)(\\d{8})(?!\\d)', name)\n",
    "    m6 = re.search(r'(?<!\\d)(\\d{6})(?!\\d)', name)\n",
    "    if m8:\n",
    "        s = m8.group(1)\n",
    "        dt = datetime.strptime(s, \"%Y%m%d\")\n",
    "        return s[:6], pd.Timestamp(dt.year, dt.month, dt.day)\n",
    "    if m6:\n",
    "        s = m6.group(1)\n",
    "        dt = datetime.strptime(s, \"%Y%m\")\n",
    "        return s, pd.Timestamp(dt.year, dt.month, 1)\n",
    "    raise ValueError(f\"Não encontrei data no nome do arquivo: {name}\")\n",
    "\n",
    "# ------------------ PROCESSAMENTO POR DOC ------------------\n",
    "\n",
    "def processar_pdf(path_pdf: Path, min_palavras: int = 8,\n",
    "                  doc_type: Optional[str] = None,\n",
    "                  yyyymm_override: Optional[str] = None) -> pd.DataFrame:\n",
    "    try:\n",
    "        yyyymm, dt = data_do_arquivo(path_pdf)\n",
    "    except Exception:\n",
    "        # Mantém compatibilidade com casos sem data — retorna vazio\n",
    "        return pd.DataFrame(columns=[\"doc\",\"dt\",\"pid\",\"texto\",\"n_palavras\"])\n",
    "\n",
    "    if yyyymm_override:\n",
    "        yyyymm = yyyymm_override\n",
    "\n",
    "    doc_type = doc_type or guess_doc_type(path_pdf.name)\n",
    "    # doc_id diferencia mês por tipo (evita colisões de cache/duplicatas)\n",
    "    doc_id = f\"{yyyymm}_{doc_type}\"\n",
    "\n",
    "    text, _removed, _n_pages = clean_pdf_text(path_pdf, doc_type)\n",
    "    if not text.strip():\n",
    "        return pd.DataFrame(columns=[\"doc\",\"dt\",\"pid\",\"texto\",\"n_palavras\"])\n",
    "\n",
    "    pars = quebrar_paragrafos(text, min_palavras=min_palavras)\n",
    "    rows = [{\"doc\": doc_id, \"dt\": dt, \"pid\": i, \"texto\": p, \"n_palavras\": len(p.split())}\n",
    "            for i, p in enumerate(pars, 1)]\n",
    "    return pd.DataFrame(rows)\n",
    "\n",
    "# ------------------ VARREDURA, CACHE E JUNÇÃO ------------------\n",
    "\n",
    "def processar_raiz(raiz: str,\n",
    "                   min_palavras: int = 8,\n",
    "                   anos: set[int] | None = {2022, 2023, 2024, 2025},\n",
    "                   cache_dir: str = \"out/estatisticas_paragrafos\",\n",
    "                   rebuild_cache: bool = False) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Saída: DataFrame com colunas [\"doc\",\"dt\",\"pid\",\"texto\",\"n_palavras\"], ordenado.\n",
    "    - \"doc\" agora é \"YYYYMM_tipo\" (ex.: \"202312_ata\", \"202406_ref\", \"202411_mensal\")\n",
    "      para evitar colisões quando há mais de um PDF no mesmo mês.\n",
    "    \"\"\"\n",
    "    raiz = Path(raiz)\n",
    "    cache = Path(cache_dir)\n",
    "    cache.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    dfs, vistos = [], set()\n",
    "\n",
    "    for pdf in sorted(raiz.rglob(\"*.pdf\")):\n",
    "        name = pdf.stem\n",
    "\n",
    "        # detecta 8d -> 6d; ou só 6d\n",
    "        m8 = re.search(r'(?<!\\d)(\\d{8})(?!\\d)', name)\n",
    "        m6 = re.search(r'(?<!\\d)(\\d{6})(?!\\d)', name)\n",
    "        if m8:\n",
    "            yyyymm = m8.group(1)[:6]\n",
    "        elif m6:\n",
    "            yyyymm = m6.group(1)\n",
    "        else:\n",
    "            continue\n",
    "\n",
    "        ano = int(yyyymm[:4])\n",
    "        if anos is not None and ano not in anos:\n",
    "            continue\n",
    "\n",
    "        tipo = guess_doc_type(name)\n",
    "        doc_key = f\"{yyyymm}_{tipo}\"\n",
    "\n",
    "        if doc_key in vistos:\n",
    "            continue\n",
    "\n",
    "        pkl_path = cache / f\"{doc_key}.pkl\"\n",
    "        if (not rebuild_cache) and pkl_path.exists():\n",
    "            try:\n",
    "                df = pd.read_pickle(pkl_path)\n",
    "            except Exception:\n",
    "                df = processar_pdf(pdf, min_palavras=min_palavras, doc_type=tipo, yyyymm_override=yyyymm)\n",
    "                df.to_pickle(pkl_path)\n",
    "        else:\n",
    "            df = processar_pdf(pdf, min_palavras=min_palavras, doc_type=tipo, yyyymm_override=yyyymm)\n",
    "            df.to_pickle(pkl_path)\n",
    "\n",
    "        if not df.empty:\n",
    "            dfs.append(df)\n",
    "            vistos.add(doc_key)\n",
    "\n",
    "    if not dfs:\n",
    "        return pd.DataFrame(columns=[\"doc\",\"dt\",\"pid\",\"texto\",\"n_palavras\"])\n",
    "\n",
    "    out = pd.concat(dfs, ignore_index=True)\n",
    "    return out.sort_values([\"dt\",\"doc\",\"pid\"]).reset_index(drop=True)\n",
    "\n",
    "# Alias para nome canônico na base consolidada\n",
    "TIPO_ALIAS_OUT = {\n",
    "    \"mensal\": \"estm\",\n",
    "    \"ata\":    \"copom\",\n",
    "    \"ref\":    \"ref\",\n",
    "}\n",
    "\n",
    "def doc_canonico(doc_str: str) -> str:\n",
    "    \"\"\"\n",
    "    Recebe 'YYYYMM_tipo' (ex.: '202403_mensal') e devolve\n",
    "    'YYYYMM_estm|copom|ref' conforme o padrão solicitado.\n",
    "    \"\"\"\n",
    "    yyyymm = doc_str[:6]\n",
    "    tipo = doc_str.rsplit(\"_\", 1)[-1]\n",
    "    return f\"{yyyymm}_{TIPO_ALIAS_OUT.get(tipo, tipo)}\"\n",
    "\n",
    "# === CONSOLIDAÇÃO POR DOCUMENTO (1 linha = 1 PDF) ===\n",
    "def montar_docs(df_paragrafos: pd.DataFrame) -> pd.DataFrame:\n",
    "    base = df_paragrafos.sort_values([\"doc\", \"pid\"]).copy()\n",
    "    df_docs = (\n",
    "        base.groupby(\"doc\")\n",
    "            .agg(\n",
    "                dt=(\"dt\", \"first\"),\n",
    "                texto=(\"texto\", lambda s: \"\\n\\n\".join(s)),\n",
    "                n_paragrafos=(\"pid\", \"count\"),\n",
    "                n_palavras=(\"n_palavras\", \"sum\"),\n",
    "            )\n",
    "            .reset_index()\n",
    "    )\n",
    "\n",
    "    # metadados\n",
    "    df_docs[\"tipo\"] = df_docs[\"doc\"].str.rsplit(\"_\", n=1).str[-1]  # ata/ref/mensal\n",
    "    df_docs[\"yyyymm\"] = df_docs[\"doc\"].str[:6]\n",
    "\n",
    "    # nome canônico solicitado\n",
    "    df_docs = df_docs.rename(columns={\"doc\": \"doc_src\"})\n",
    "    df_docs[\"doc\"] = df_docs[\"doc_src\"].apply(doc_canonico)\n",
    "\n",
    "    # reordenar colunas (opcional)\n",
    "    cols = [\"doc\", \"doc_src\", \"yyyymm\", \"tipo\", \"dt\", \"n_paragrafos\", \"n_palavras\", \"texto\"]\n",
    "    return df_docs[cols]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85347f6a",
   "metadata": {},
   "source": [
    "**O que faz:**\n",
    "\n",
    "1. Executa a coleta/extração de parágrafos e guarda em `df_paragrafos`.\n",
    "2. Exporta para `paragrafos.csv`.\n",
    "\n",
    "**Por quê:** persistir em CSV facilita auditoria e uso em outras ferramentas.\n",
    "\n",
    "**Saída:** arquivo `paragrafos.csv` no diretório atual.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f80a4fcd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>doc</th>\n",
       "      <th>doc_src</th>\n",
       "      <th>yyyymm</th>\n",
       "      <th>tipo</th>\n",
       "      <th>dt</th>\n",
       "      <th>n_paragrafos</th>\n",
       "      <th>n_palavras</th>\n",
       "      <th>texto</th>\n",
       "      <th>sentimento</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>202201_estm</td>\n",
       "      <td>202201_mensal</td>\n",
       "      <td>202201</td>\n",
       "      <td>mensal</td>\n",
       "      <td>2022-01-01</td>\n",
       "      <td>4</td>\n",
       "      <td>1536</td>\n",
       "      <td>1. Crédito ampliado ao setor não financeiro Em...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>202202_estm</td>\n",
       "      <td>202202_mensal</td>\n",
       "      <td>202202</td>\n",
       "      <td>mensal</td>\n",
       "      <td>2022-02-01</td>\n",
       "      <td>5</td>\n",
       "      <td>1686</td>\n",
       "      <td>1. Crédito ampliado ao setor não financeiro Em...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>202203_estm</td>\n",
       "      <td>202203_mensal</td>\n",
       "      <td>202203</td>\n",
       "      <td>mensal</td>\n",
       "      <td>2022-03-01</td>\n",
       "      <td>3</td>\n",
       "      <td>1220</td>\n",
       "      <td>1. Crédito ampliado ao setor não financeiro Em...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>202205_estm</td>\n",
       "      <td>202205_mensal</td>\n",
       "      <td>202205</td>\n",
       "      <td>mensal</td>\n",
       "      <td>2022-05-01</td>\n",
       "      <td>4</td>\n",
       "      <td>1384</td>\n",
       "      <td>1. Crédito ampliado ao setor não financeiro Em...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>202207_estm</td>\n",
       "      <td>202207_mensal</td>\n",
       "      <td>202207</td>\n",
       "      <td>mensal</td>\n",
       "      <td>2022-07-01</td>\n",
       "      <td>4</td>\n",
       "      <td>1391</td>\n",
       "      <td>1. Crédito ampliado ao setor não financeiro Em...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>202209_estm</td>\n",
       "      <td>202209_mensal</td>\n",
       "      <td>202209</td>\n",
       "      <td>mensal</td>\n",
       "      <td>2022-09-01</td>\n",
       "      <td>4</td>\n",
       "      <td>1464</td>\n",
       "      <td>1. Crédito ampliado ao setor não financeiro Em...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>202210_estm</td>\n",
       "      <td>202210_mensal</td>\n",
       "      <td>202210</td>\n",
       "      <td>mensal</td>\n",
       "      <td>2022-10-01</td>\n",
       "      <td>5</td>\n",
       "      <td>1894</td>\n",
       "      <td>1. Crédito ampliado ao setor não financeiro Em...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>202211_estm</td>\n",
       "      <td>202211_mensal</td>\n",
       "      <td>202211</td>\n",
       "      <td>mensal</td>\n",
       "      <td>2022-11-01</td>\n",
       "      <td>4</td>\n",
       "      <td>1536</td>\n",
       "      <td>1. Crédito ampliado ao setor não financeiro Em...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>202212_estm</td>\n",
       "      <td>202212_mensal</td>\n",
       "      <td>202212</td>\n",
       "      <td>mensal</td>\n",
       "      <td>2022-12-01</td>\n",
       "      <td>4</td>\n",
       "      <td>1299</td>\n",
       "      <td>1. Crédito ampliado ao setor não financeiro Em...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>202301_estm</td>\n",
       "      <td>202301_mensal</td>\n",
       "      <td>202301</td>\n",
       "      <td>mensal</td>\n",
       "      <td>2023-01-01</td>\n",
       "      <td>5</td>\n",
       "      <td>1535</td>\n",
       "      <td>1. Crédito ampliado ao setor não financeiro Em...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>202302_estm</td>\n",
       "      <td>202302_mensal</td>\n",
       "      <td>202302</td>\n",
       "      <td>mensal</td>\n",
       "      <td>2023-02-01</td>\n",
       "      <td>6</td>\n",
       "      <td>2111</td>\n",
       "      <td>1. Crédito ampliado ao setor não financeiro Em...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>202303_estm</td>\n",
       "      <td>202303_mensal</td>\n",
       "      <td>202303</td>\n",
       "      <td>mensal</td>\n",
       "      <td>2023-03-01</td>\n",
       "      <td>4</td>\n",
       "      <td>1520</td>\n",
       "      <td>1. Crédito ampliado ao setor não financeiro Em...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>202304_estm</td>\n",
       "      <td>202304_mensal</td>\n",
       "      <td>202304</td>\n",
       "      <td>mensal</td>\n",
       "      <td>2023-04-01</td>\n",
       "      <td>4</td>\n",
       "      <td>1435</td>\n",
       "      <td>1. Crédito ampliado ao setor não financeiro Em...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>202305_estm</td>\n",
       "      <td>202305_mensal</td>\n",
       "      <td>202305</td>\n",
       "      <td>mensal</td>\n",
       "      <td>2023-05-01</td>\n",
       "      <td>4</td>\n",
       "      <td>1440</td>\n",
       "      <td>1. Crédito ampliado ao setor não financeiro Em...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>202306_estm</td>\n",
       "      <td>202306_mensal</td>\n",
       "      <td>202306</td>\n",
       "      <td>mensal</td>\n",
       "      <td>2023-06-01</td>\n",
       "      <td>4</td>\n",
       "      <td>1488</td>\n",
       "      <td>1. Crédito ampliado ao setor não financeiro Em...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>202307_estm</td>\n",
       "      <td>202307_mensal</td>\n",
       "      <td>202307</td>\n",
       "      <td>mensal</td>\n",
       "      <td>2023-07-01</td>\n",
       "      <td>4</td>\n",
       "      <td>1401</td>\n",
       "      <td>1. Crédito ampliado ao setor não financeiro Em...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>202308_estm</td>\n",
       "      <td>202308_mensal</td>\n",
       "      <td>202308</td>\n",
       "      <td>mensal</td>\n",
       "      <td>2023-08-01</td>\n",
       "      <td>4</td>\n",
       "      <td>1564</td>\n",
       "      <td>1. Crédito ampliado ao setor não financeiro Em...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>202309_estm</td>\n",
       "      <td>202309_mensal</td>\n",
       "      <td>202309</td>\n",
       "      <td>mensal</td>\n",
       "      <td>2023-09-01</td>\n",
       "      <td>5</td>\n",
       "      <td>1734</td>\n",
       "      <td>1. Crédito ampliado ao setor não financeiro Em...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>202310_estm</td>\n",
       "      <td>202310_mensal</td>\n",
       "      <td>202310</td>\n",
       "      <td>mensal</td>\n",
       "      <td>2023-10-01</td>\n",
       "      <td>4</td>\n",
       "      <td>1500</td>\n",
       "      <td>1. Crédito ampliado ao setor não financeiro Em...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>202311_estm</td>\n",
       "      <td>202311_mensal</td>\n",
       "      <td>202311</td>\n",
       "      <td>mensal</td>\n",
       "      <td>2023-11-01</td>\n",
       "      <td>4</td>\n",
       "      <td>1522</td>\n",
       "      <td>1. Crédito ampliado ao setor não financeiro Em...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>202312_estm</td>\n",
       "      <td>202312_mensal</td>\n",
       "      <td>202312</td>\n",
       "      <td>mensal</td>\n",
       "      <td>2023-12-01</td>\n",
       "      <td>4</td>\n",
       "      <td>1428</td>\n",
       "      <td>1. Crédito ampliado ao setor não financeiro Em...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>202401_estm</td>\n",
       "      <td>202401_mensal</td>\n",
       "      <td>202401</td>\n",
       "      <td>mensal</td>\n",
       "      <td>2024-01-01</td>\n",
       "      <td>5</td>\n",
       "      <td>1780</td>\n",
       "      <td>1. Crédito ampliado ao setor não financeiro Em...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>202402_estm</td>\n",
       "      <td>202402_mensal</td>\n",
       "      <td>202402</td>\n",
       "      <td>mensal</td>\n",
       "      <td>2024-02-01</td>\n",
       "      <td>4</td>\n",
       "      <td>1658</td>\n",
       "      <td>1. Crédito ampliado ao setor não financeiro Em...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>202403_estm</td>\n",
       "      <td>202403_mensal</td>\n",
       "      <td>202403</td>\n",
       "      <td>mensal</td>\n",
       "      <td>2024-03-01</td>\n",
       "      <td>5</td>\n",
       "      <td>1655</td>\n",
       "      <td>1. Crédito ampliado ao setor não financeiro Em...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>202404_estm</td>\n",
       "      <td>202404_mensal</td>\n",
       "      <td>202404</td>\n",
       "      <td>mensal</td>\n",
       "      <td>2024-04-01</td>\n",
       "      <td>5</td>\n",
       "      <td>2138</td>\n",
       "      <td>1. Crédito ampliado ao setor não financeiro Em...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>202405_estm</td>\n",
       "      <td>202405_mensal</td>\n",
       "      <td>202405</td>\n",
       "      <td>mensal</td>\n",
       "      <td>2024-05-01</td>\n",
       "      <td>5</td>\n",
       "      <td>2145</td>\n",
       "      <td>1. Crédito ampliado ao setor não financeiro Em...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>202406_estm</td>\n",
       "      <td>202406_mensal</td>\n",
       "      <td>202406</td>\n",
       "      <td>mensal</td>\n",
       "      <td>2024-06-01</td>\n",
       "      <td>7</td>\n",
       "      <td>2278</td>\n",
       "      <td>1. Crédito ampliado ao setor não financeiro Em...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>202407_estm</td>\n",
       "      <td>202407_mensal</td>\n",
       "      <td>202407</td>\n",
       "      <td>mensal</td>\n",
       "      <td>2024-07-01</td>\n",
       "      <td>6</td>\n",
       "      <td>2800</td>\n",
       "      <td>1. Crédito ampliado ao setor não financeiro Em...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>202408_estm</td>\n",
       "      <td>202408_mensal</td>\n",
       "      <td>202408</td>\n",
       "      <td>mensal</td>\n",
       "      <td>2024-08-01</td>\n",
       "      <td>5</td>\n",
       "      <td>2068</td>\n",
       "      <td>1. Crédito ampliado ao setor não financeiro Em...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>202409_estm</td>\n",
       "      <td>202409_mensal</td>\n",
       "      <td>202409</td>\n",
       "      <td>mensal</td>\n",
       "      <td>2024-09-01</td>\n",
       "      <td>7</td>\n",
       "      <td>2666</td>\n",
       "      <td>1. Crédito ampliado ao setor não financeiro Em...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>202410_estm</td>\n",
       "      <td>202410_mensal</td>\n",
       "      <td>202410</td>\n",
       "      <td>mensal</td>\n",
       "      <td>2024-10-01</td>\n",
       "      <td>5</td>\n",
       "      <td>2033</td>\n",
       "      <td>1. Crédito ampliado ao setor não financeiro Em...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>202411_estm</td>\n",
       "      <td>202411_mensal</td>\n",
       "      <td>202411</td>\n",
       "      <td>mensal</td>\n",
       "      <td>2024-11-01</td>\n",
       "      <td>7</td>\n",
       "      <td>2368</td>\n",
       "      <td>1. Crédito ampliado ao setor não financeiro Em...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>202412_estm</td>\n",
       "      <td>202412_mensal</td>\n",
       "      <td>202412</td>\n",
       "      <td>mensal</td>\n",
       "      <td>2024-12-01</td>\n",
       "      <td>7</td>\n",
       "      <td>2296</td>\n",
       "      <td>1. Crédito ampliado ao setor não financeiro Em...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>202501_estm</td>\n",
       "      <td>202501_mensal</td>\n",
       "      <td>202501</td>\n",
       "      <td>mensal</td>\n",
       "      <td>2025-01-01</td>\n",
       "      <td>6</td>\n",
       "      <td>2026</td>\n",
       "      <td>Errata: em 28 de janeiro de 2025, a informação...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>202502_estm</td>\n",
       "      <td>202502_mensal</td>\n",
       "      <td>202502</td>\n",
       "      <td>mensal</td>\n",
       "      <td>2025-02-01</td>\n",
       "      <td>7</td>\n",
       "      <td>2722</td>\n",
       "      <td>1. Crédito ampliado ao setor não financeiro Em...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>202503_estm</td>\n",
       "      <td>202503_mensal</td>\n",
       "      <td>202503</td>\n",
       "      <td>mensal</td>\n",
       "      <td>2025-03-01</td>\n",
       "      <td>5</td>\n",
       "      <td>1991</td>\n",
       "      <td>1. Crédito ampliado ao setor não financeiro Em...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>202504_estm</td>\n",
       "      <td>202504_mensal</td>\n",
       "      <td>202504</td>\n",
       "      <td>mensal</td>\n",
       "      <td>2025-04-01</td>\n",
       "      <td>5</td>\n",
       "      <td>2076</td>\n",
       "      <td>1. Crédito ampliado ao setor não financeiro Em...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>202505_estm</td>\n",
       "      <td>202505_mensal</td>\n",
       "      <td>202505</td>\n",
       "      <td>mensal</td>\n",
       "      <td>2025-05-01</td>\n",
       "      <td>5</td>\n",
       "      <td>2067</td>\n",
       "      <td>1. Crédito ampliado ao setor não financeiro Em...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>202506_estm</td>\n",
       "      <td>202506_mensal</td>\n",
       "      <td>202506</td>\n",
       "      <td>mensal</td>\n",
       "      <td>2025-06-01</td>\n",
       "      <td>8</td>\n",
       "      <td>2375</td>\n",
       "      <td>1. Crédito ampliado ao setor não financeiro Em...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>202507_estm</td>\n",
       "      <td>202507_mensal</td>\n",
       "      <td>202507</td>\n",
       "      <td>mensal</td>\n",
       "      <td>2025-07-01</td>\n",
       "      <td>5</td>\n",
       "      <td>2017</td>\n",
       "      <td>1. Crédito ampliado ao setor não financeiro Em...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>202508_estm</td>\n",
       "      <td>202508_mensal</td>\n",
       "      <td>202508</td>\n",
       "      <td>mensal</td>\n",
       "      <td>2025-08-01</td>\n",
       "      <td>5</td>\n",
       "      <td>1836</td>\n",
       "      <td>1. Crédito ampliado ao setor não financeiro Em...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>202509_estm</td>\n",
       "      <td>202509_mensal</td>\n",
       "      <td>202509</td>\n",
       "      <td>mensal</td>\n",
       "      <td>2025-09-01</td>\n",
       "      <td>7</td>\n",
       "      <td>1993</td>\n",
       "      <td>1. Crédito ampliado ao setor não financeiro Em...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            doc        doc_src  yyyymm    tipo         dt  n_paragrafos  \\\n",
       "0   202201_estm  202201_mensal  202201  mensal 2022-01-01             4   \n",
       "1   202202_estm  202202_mensal  202202  mensal 2022-02-01             5   \n",
       "2   202203_estm  202203_mensal  202203  mensal 2022-03-01             3   \n",
       "3   202205_estm  202205_mensal  202205  mensal 2022-05-01             4   \n",
       "4   202207_estm  202207_mensal  202207  mensal 2022-07-01             4   \n",
       "5   202209_estm  202209_mensal  202209  mensal 2022-09-01             4   \n",
       "6   202210_estm  202210_mensal  202210  mensal 2022-10-01             5   \n",
       "7   202211_estm  202211_mensal  202211  mensal 2022-11-01             4   \n",
       "8   202212_estm  202212_mensal  202212  mensal 2022-12-01             4   \n",
       "9   202301_estm  202301_mensal  202301  mensal 2023-01-01             5   \n",
       "10  202302_estm  202302_mensal  202302  mensal 2023-02-01             6   \n",
       "11  202303_estm  202303_mensal  202303  mensal 2023-03-01             4   \n",
       "12  202304_estm  202304_mensal  202304  mensal 2023-04-01             4   \n",
       "13  202305_estm  202305_mensal  202305  mensal 2023-05-01             4   \n",
       "14  202306_estm  202306_mensal  202306  mensal 2023-06-01             4   \n",
       "15  202307_estm  202307_mensal  202307  mensal 2023-07-01             4   \n",
       "16  202308_estm  202308_mensal  202308  mensal 2023-08-01             4   \n",
       "17  202309_estm  202309_mensal  202309  mensal 2023-09-01             5   \n",
       "18  202310_estm  202310_mensal  202310  mensal 2023-10-01             4   \n",
       "19  202311_estm  202311_mensal  202311  mensal 2023-11-01             4   \n",
       "20  202312_estm  202312_mensal  202312  mensal 2023-12-01             4   \n",
       "21  202401_estm  202401_mensal  202401  mensal 2024-01-01             5   \n",
       "22  202402_estm  202402_mensal  202402  mensal 2024-02-01             4   \n",
       "23  202403_estm  202403_mensal  202403  mensal 2024-03-01             5   \n",
       "24  202404_estm  202404_mensal  202404  mensal 2024-04-01             5   \n",
       "25  202405_estm  202405_mensal  202405  mensal 2024-05-01             5   \n",
       "26  202406_estm  202406_mensal  202406  mensal 2024-06-01             7   \n",
       "27  202407_estm  202407_mensal  202407  mensal 2024-07-01             6   \n",
       "28  202408_estm  202408_mensal  202408  mensal 2024-08-01             5   \n",
       "29  202409_estm  202409_mensal  202409  mensal 2024-09-01             7   \n",
       "30  202410_estm  202410_mensal  202410  mensal 2024-10-01             5   \n",
       "31  202411_estm  202411_mensal  202411  mensal 2024-11-01             7   \n",
       "32  202412_estm  202412_mensal  202412  mensal 2024-12-01             7   \n",
       "33  202501_estm  202501_mensal  202501  mensal 2025-01-01             6   \n",
       "34  202502_estm  202502_mensal  202502  mensal 2025-02-01             7   \n",
       "35  202503_estm  202503_mensal  202503  mensal 2025-03-01             5   \n",
       "36  202504_estm  202504_mensal  202504  mensal 2025-04-01             5   \n",
       "37  202505_estm  202505_mensal  202505  mensal 2025-05-01             5   \n",
       "38  202506_estm  202506_mensal  202506  mensal 2025-06-01             8   \n",
       "39  202507_estm  202507_mensal  202507  mensal 2025-07-01             5   \n",
       "40  202508_estm  202508_mensal  202508  mensal 2025-08-01             5   \n",
       "41  202509_estm  202509_mensal  202509  mensal 2025-09-01             7   \n",
       "\n",
       "    n_palavras                                              texto  sentimento  \n",
       "0         1536  1. Crédito ampliado ao setor não financeiro Em...         0.0  \n",
       "1         1686  1. Crédito ampliado ao setor não financeiro Em...         0.0  \n",
       "2         1220  1. Crédito ampliado ao setor não financeiro Em...         0.0  \n",
       "3         1384  1. Crédito ampliado ao setor não financeiro Em...         0.0  \n",
       "4         1391  1. Crédito ampliado ao setor não financeiro Em...         0.0  \n",
       "5         1464  1. Crédito ampliado ao setor não financeiro Em...         0.0  \n",
       "6         1894  1. Crédito ampliado ao setor não financeiro Em...         0.0  \n",
       "7         1536  1. Crédito ampliado ao setor não financeiro Em...         0.0  \n",
       "8         1299  1. Crédito ampliado ao setor não financeiro Em...         0.0  \n",
       "9         1535  1. Crédito ampliado ao setor não financeiro Em...         0.0  \n",
       "10        2111  1. Crédito ampliado ao setor não financeiro Em...         0.0  \n",
       "11        1520  1. Crédito ampliado ao setor não financeiro Em...         0.0  \n",
       "12        1435  1. Crédito ampliado ao setor não financeiro Em...         0.0  \n",
       "13        1440  1. Crédito ampliado ao setor não financeiro Em...         0.0  \n",
       "14        1488  1. Crédito ampliado ao setor não financeiro Em...         0.0  \n",
       "15        1401  1. Crédito ampliado ao setor não financeiro Em...         0.0  \n",
       "16        1564  1. Crédito ampliado ao setor não financeiro Em...         0.0  \n",
       "17        1734  1. Crédito ampliado ao setor não financeiro Em...         0.0  \n",
       "18        1500  1. Crédito ampliado ao setor não financeiro Em...         0.0  \n",
       "19        1522  1. Crédito ampliado ao setor não financeiro Em...         0.0  \n",
       "20        1428  1. Crédito ampliado ao setor não financeiro Em...         0.0  \n",
       "21        1780  1. Crédito ampliado ao setor não financeiro Em...         0.0  \n",
       "22        1658  1. Crédito ampliado ao setor não financeiro Em...         0.0  \n",
       "23        1655  1. Crédito ampliado ao setor não financeiro Em...         0.0  \n",
       "24        2138  1. Crédito ampliado ao setor não financeiro Em...         0.0  \n",
       "25        2145  1. Crédito ampliado ao setor não financeiro Em...         0.0  \n",
       "26        2278  1. Crédito ampliado ao setor não financeiro Em...         0.0  \n",
       "27        2800  1. Crédito ampliado ao setor não financeiro Em...         0.0  \n",
       "28        2068  1. Crédito ampliado ao setor não financeiro Em...         0.0  \n",
       "29        2666  1. Crédito ampliado ao setor não financeiro Em...         0.0  \n",
       "30        2033  1. Crédito ampliado ao setor não financeiro Em...         0.0  \n",
       "31        2368  1. Crédito ampliado ao setor não financeiro Em...         0.0  \n",
       "32        2296  1. Crédito ampliado ao setor não financeiro Em...         0.0  \n",
       "33        2026  Errata: em 28 de janeiro de 2025, a informação...         0.0  \n",
       "34        2722  1. Crédito ampliado ao setor não financeiro Em...         0.0  \n",
       "35        1991  1. Crédito ampliado ao setor não financeiro Em...         0.0  \n",
       "36        2076  1. Crédito ampliado ao setor não financeiro Em...         0.0  \n",
       "37        2067  1. Crédito ampliado ao setor não financeiro Em...         0.0  \n",
       "38        2375  1. Crédito ampliado ao setor não financeiro Em...         0.0  \n",
       "39        2017  1. Crédito ampliado ao setor não financeiro Em...         0.0  \n",
       "40        1836  1. Crédito ampliado ao setor não financeiro Em...         0.0  \n",
       "41        1993  1. Crédito ampliado ao setor não financeiro Em...         0.0  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_paragrafos = processar_raiz(\"data/estatisticas\", anos={2022, 2023, 2024, 2025})\n",
    "df_docs = montar_docs(df_paragrafos)\n",
    "df_docs\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a4dba458",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>doc</th>\n",
       "      <th>doc_src</th>\n",
       "      <th>yyyymm</th>\n",
       "      <th>tipo</th>\n",
       "      <th>dt</th>\n",
       "      <th>n_paragrafos</th>\n",
       "      <th>n_palavras</th>\n",
       "      <th>texto</th>\n",
       "      <th>sentimento</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [doc, doc_src, yyyymm, tipo, dt, n_paragrafos, n_palavras, texto, sentimento]\n",
       "Index: []"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_paragrafos = processar_raiz(\"data/atas\", anos={2022, 2023, 2024, 2025})\n",
    "df_docs = montar_docs(df_paragrafos)\n",
    "df_docs[\"sentimento\"] = df_docs[\"texto\"].apply(indice_sentimento)\n",
    "df_docs.shape\n",
    "df_docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6ec93cc2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>doc</th>\n",
       "      <th>dt</th>\n",
       "      <th>texto</th>\n",
       "      <th>n_paragrafos</th>\n",
       "      <th>n_palavras</th>\n",
       "      <th>tipo</th>\n",
       "      <th>yyyymm</th>\n",
       "      <th>sentimento</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [doc, dt, texto, n_paragrafos, n_palavras, tipo, yyyymm, sentimento]\n",
       "Index: []"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_paragrafos = processar_raiz(\"data/ref\")\n",
    "df_docs = montar_docs(df_paragrafos)\n",
    "df_docs[\"sentimento\"] = df_docs[\"texto\"].apply(indice_sentimento)\n",
    "df_docs.shape\n",
    "df_docs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7a2599c",
   "metadata": {},
   "source": [
    "# 2.1) Limpando títulos desnecessários\n",
    "\n",
    "> Seção (markdown) que introduz a **limpeza textual**: remoção de cabeçalhos/legendas, fusão de parágrafos curtos etc.\n",
    "\n",
    "---\n",
    "## Bloco 4 — Funções utilitárias de limpeza e fusão\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3177f3cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# --- helpers ---\n",
    "WORD_RE = re.compile(r\"\\b\\w+\\b\", flags=re.UNICODE)\n",
    "\n",
    "def count_words(s: str) -> int:\n",
    "    return len(WORD_RE.findall(s or \"\"))\n",
    "\n",
    "def caps_ratio(s: str) -> float:\n",
    "    toks = re.findall(r\"\\b[^\\W\\d_]+\\b\", s or \"\", flags=re.UNICODE)\n",
    "    if not toks: \n",
    "        return 0.0\n",
    "    return sum(t.isupper() for t in toks) / len(toks)\n",
    "\n",
    "_HEADING_PREFIXES = (\n",
    "    \"nota para a imprensa\",\n",
    "    \"sumário\",\"sumario\",\"resumo\",\n",
    "    \"apresentação\",\"apresentacao\",\n",
    "    \"introdução\",\"introducao\",\n",
    "    \"conclusão\",\"conclusoes\",\"conclusao\",\n",
    ")\n",
    "_CAPTION_HINTS = (\"figura\",\"gráfico\",\"grafico\",\"tabela\",\"fonte:\")\n",
    "\n",
    "def is_heading(text: str) -> bool:\n",
    "    s = (text or \"\").strip()\n",
    "    if not s:\n",
    "        return True\n",
    "    # \"2.\" ou \"2.3.\" no início\n",
    "    if re.match(r\"^\\d+(\\.\\d+)*\\s\", s):\n",
    "        return True\n",
    "    low = s.lower()\n",
    "    if low.startswith(_HEADING_PREFIXES):\n",
    "        return True\n",
    "    if any(k in low for k in _CAPTION_HINTS):\n",
    "        return True\n",
    "    # muito MAIÚSCULO (título), curto e sem pontuação final\n",
    "    if caps_ratio(s) > 0.6 and len(s.split()) <= 20:\n",
    "        return True\n",
    "    if len(s.split()) < 15 and not re.search(r\"[.!?;:]\\s*$\", s):\n",
    "        return True\n",
    "    return False\n",
    "\n",
    "def clean_text_unit(s: str) -> str:\n",
    "    s = (s or \"\").replace(\"\\r\",\"\")\n",
    "    s = re.sub(r\"[ \\t]+\", \" \", s).strip()\n",
    "    # remove numeração de seção no início\n",
    "    s = re.sub(r\"^\\d+(\\.\\d+)*\\s+\", \"\", s)\n",
    "    return s\n",
    "\n",
    "def _fuse_short_paragraphs(df_group: pd.DataFrame, min_words: int = 8, max_merge_span: int = 3) -> pd.DataFrame:\n",
    "    \"\"\"Funde parágrafos consecutivos curtos até atingir min_words (no máx. 3 blocos por fusão).\"\"\"\n",
    "    rows, buf, buf_words, buf_span = [], [], 0, 0\n",
    "    for _, r in df_group.sort_values(\"pid\").iterrows():\n",
    "        txt = str(r[\"texto\"])\n",
    "        w = count_words(txt)\n",
    "        if w >= min_words:\n",
    "            if buf and buf_words >= min_words:\n",
    "                rows.append({\"texto\": \" \".join(buf)})\n",
    "            buf, buf_words, buf_span = [], 0, 0\n",
    "            rows.append({\"texto\": txt})\n",
    "        else:\n",
    "            buf.append(txt); buf_words += w; buf_span += 1\n",
    "            if buf_words >= min_words or buf_span >= max_merge_span:\n",
    "                rows.append({\"texto\": \" \".join(buf)})\n",
    "                buf, buf_words, buf_span = [], 0, 0\n",
    "    if buf and buf_words >= min_words:\n",
    "        rows.append({\"texto\": \" \".join(buf)})\n",
    "    out = pd.DataFrame(rows)\n",
    "    out[\"pid\"] = np.arange(1, len(out)+1, dtype=int)\n",
    "    return out\n",
    "\n",
    "def limpar_paragrafos(df: pd.DataFrame, min_palavras: int = 8, max_merge_span: int = 3) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Entrada: df_paragrafos com colunas ['doc','dt','pid','texto','n_palavras'].\n",
    "    Saída: df_limpo com mesmas colunas, mas:\n",
    "      - headings/legendas removidos\n",
    "      - parágrafos curtos fundidos\n",
    "      - mínimo de 8 palavras garantido\n",
    "      - pid reindexado por (doc, dt)\n",
    "    \"\"\"\n",
    "    # checagem \n",
    "    for c in [\"doc\",\"dt\",\"pid\",\"texto\",\"n_palavras\"]:\n",
    "        if c not in df.columns:\n",
    "            raise ValueError(f\"Coluna obrigatória ausente: {c}\")\n",
    "\n",
    "    dfx = df.copy()\n",
    "    dfx[\"doc\"] = dfx[\"doc\"].astype(str)\n",
    "    dfx[\"dt\"] = pd.to_datetime(dfx[\"dt\"], errors=\"coerce\")\n",
    "    dfx[\"pid\"] = pd.to_numeric(dfx[\"pid\"], errors=\"coerce\").fillna(0).astype(int)\n",
    "    dfx[\"texto\"] = dfx[\"texto\"].astype(str)\n",
    "\n",
    "    # 1) remove vazios/sem letras\n",
    "    mask_nonempty = dfx[\"texto\"].str.strip().ne(\"\")\n",
    "    mask_alpha = dfx[\"texto\"].str.contains(r\"[A-Za-zÀ-ÖØ-öø-ÿ]\", regex=True)\n",
    "    dfx = dfx[mask_nonempty & mask_alpha].copy()\n",
    "\n",
    "    # 2) remove headings/legendas\n",
    "    dfx = dfx[~dfx[\"texto\"].map(is_heading)].copy()\n",
    "\n",
    "    # 3) limpeza fina + recount\n",
    "    dfx[\"texto\"] = dfx[\"texto\"].map(clean_text_unit)\n",
    "    dfx[\"n_palavras\"] = dfx[\"texto\"].map(count_words).astype(int)\n",
    "\n",
    "    # 4) fusão de curtas por (doc, dt)\n",
    "    groups = []\n",
    "    for (doc, dt), g in dfx.sort_values([\"doc\",\"pid\"]).groupby([\"doc\",\"dt\"], sort=False):\n",
    "        g2 = _fuse_short_paragraphs(g[[\"pid\",\"texto\"]], min_words=min_palavras, max_merge_span=max_merge_span)\n",
    "        g2[\"doc\"], g2[\"dt\"] = doc, dt\n",
    "        groups.append(g2)\n",
    "    if groups:\n",
    "        dfx = pd.concat(groups, ignore_index=True)\n",
    "    else:\n",
    "        # nenhum grupo → retorna vazio com colunas padrão\n",
    "        return dfx.assign(n_palavras=pd.Series(dtype=int))[[\"doc\",\"dt\",\"pid\",\"texto\",\"n_palavras\"]]\n",
    "\n",
    "    # 5) recount + mínimo final\n",
    "    dfx[\"texto\"] = dfx[\"texto\"].map(clean_text_unit)\n",
    "    dfx[\"n_palavras\"] = dfx[\"texto\"].map(count_words).astype(int)\n",
    "    dfx = dfx[dfx[\"n_palavras\"] >= min_palavras].copy()\n",
    "\n",
    "    # 6) ordena e reindexa pid por doc\n",
    "    dfx = dfx.sort_values([\"dt\",\"doc\",\"pid\"]).reset_index(drop=True)\n",
    "    dfx[\"pid\"] = dfx.groupby([\"doc\",\"dt\"]).cumcount() + 1\n",
    "    return dfx[[\"doc\",\"dt\",\"pid\",\"texto\",\"n_palavras\"]]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f096660",
   "metadata": {},
   "source": [
    "**O que faz (principais utilitários):**\n",
    "\n",
    "* `count_words` — conta **palavras** (tokens) no texto.\n",
    "* `caps_ratio` — mede proporção de **palavras em MAIÚSCULAS** (útil para detectar títulos).\n",
    "* `is_heading` — heurística para filtrar **títulos/legendas** (ex.: começa com numeração “2.3”, contém “Figura/Tabela”, alto `caps_ratio`, sem pontuação final).\n",
    "* `clean_text_unit` — limpeza fina: remove quebras, espaços excessivos, numeração de seção.\n",
    "* `_fuse_short_paragraphs` — **funde parágrafos muito curtos** (até atingir `min_words`, limitando `max_merge_span`).\n",
    "* `limpar_paragrafos` — **pipeline** de limpeza:\n",
    "\n",
    "  1. remove vazios/sem letras,\n",
    "  2. remove headings/legendas,\n",
    "  3. limpeza fina + **reconta palavras**,\n",
    "  4. funde curtos **por (doc, dt)**,\n",
    "  5. reforça mínimo de palavras,\n",
    "  6. **reindexa `pid`** (posição do parágrafo no documento/data).\n",
    "\n",
    "**Conceitos rápidos:**\n",
    "\n",
    "* **Heurística**: regra prática que funciona “na maioria dos casos”.\n",
    "* **Reindexar `pid`**: renumerar a ordem dos parágrafos após limpeza/fusão para manter consistência.\n",
    "\n",
    "**Saída:** funções prontas para uso; nenhuma tabela imediata.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d81c8b7",
   "metadata": {},
   "source": [
    "## Bloco 5 — Aplicação da limpeza e amostra"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9f04029b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1079, 5) → (793, 5)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>doc</th>\n",
       "      <th>dt</th>\n",
       "      <th>pid</th>\n",
       "      <th>texto</th>\n",
       "      <th>n_palavras</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>202201</td>\n",
       "      <td>2022-01-01</td>\n",
       "      <td>1</td>\n",
       "      <td>Em 2021, o saldo do crédito ampliado ao setor ...</td>\n",
       "      <td>250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>202201</td>\n",
       "      <td>2022-01-01</td>\n",
       "      <td>2</td>\n",
       "      <td>O volume de crédito do SFN alcançou R$4,7 tril...</td>\n",
       "      <td>206</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>202201</td>\n",
       "      <td>2022-01-01</td>\n",
       "      <td>3</td>\n",
       "      <td>O crédito livre às famílias atingiu R$ 1,5 tri...</td>\n",
       "      <td>56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>202201</td>\n",
       "      <td>2022-01-01</td>\n",
       "      <td>4</td>\n",
       "      <td>Em 2021, o crédito direcionado atingiu R$ 1, 9...</td>\n",
       "      <td>166</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>202201</td>\n",
       "      <td>2022-01-01</td>\n",
       "      <td>5</td>\n",
       "      <td>O Indicador de Custo do Crédito (ICC), que med...</td>\n",
       "      <td>93</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>202201</td>\n",
       "      <td>2022-01-01</td>\n",
       "      <td>6</td>\n",
       "      <td>A taxa média de juros das contratações finaliz...</td>\n",
       "      <td>203</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>202201</td>\n",
       "      <td>2022-01-01</td>\n",
       "      <td>7</td>\n",
       "      <td>A inadimplência do crédito geral atingiu 2, 3%...</td>\n",
       "      <td>59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>202201</td>\n",
       "      <td>2022-01-01</td>\n",
       "      <td>8</td>\n",
       "      <td>3. Agregados monetários Em 2021, a base monetá...</td>\n",
       "      <td>363</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>202201</td>\n",
       "      <td>2022-01-01</td>\n",
       "      <td>9</td>\n",
       "      <td>De acordo com a Política de Revisão das Estatí...</td>\n",
       "      <td>85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>202201</td>\n",
       "      <td>2022-01-01</td>\n",
       "      <td>10</td>\n",
       "      <td>i) Crédito por setor de atividade econômica : ...</td>\n",
       "      <td>101</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      doc         dt  pid                                              texto  \\\n",
       "0  202201 2022-01-01    1  Em 2021, o saldo do crédito ampliado ao setor ...   \n",
       "1  202201 2022-01-01    2  O volume de crédito do SFN alcançou R$4,7 tril...   \n",
       "2  202201 2022-01-01    3  O crédito livre às famílias atingiu R$ 1,5 tri...   \n",
       "3  202201 2022-01-01    4  Em 2021, o crédito direcionado atingiu R$ 1, 9...   \n",
       "4  202201 2022-01-01    5  O Indicador de Custo do Crédito (ICC), que med...   \n",
       "5  202201 2022-01-01    6  A taxa média de juros das contratações finaliz...   \n",
       "6  202201 2022-01-01    7  A inadimplência do crédito geral atingiu 2, 3%...   \n",
       "7  202201 2022-01-01    8  3. Agregados monetários Em 2021, a base monetá...   \n",
       "8  202201 2022-01-01    9  De acordo com a Política de Revisão das Estatí...   \n",
       "9  202201 2022-01-01   10  i) Crédito por setor de atividade econômica : ...   \n",
       "\n",
       "   n_palavras  \n",
       "0         250  \n",
       "1         206  \n",
       "2          56  \n",
       "3         166  \n",
       "4          93  \n",
       "5         203  \n",
       "6          59  \n",
       "7         363  \n",
       "8          85  \n",
       "9         101  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# se você já tem df_paragrafos carregado:\n",
    "df_paragrafos_limpos = limpar_paragrafos(df_paragrafos, min_palavras=8, max_merge_span=3)\n",
    "\n",
    "# checagem rápida\n",
    "print(df_paragrafos.shape, \"→\", df_paragrafos_limpos.shape)\n",
    "display(df_paragrafos_limpos.head(10))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09996d2e",
   "metadata": {},
   "source": [
    "**O que faz:** aplica a limpeza completa sobre `df_paragrafos`, checa o **efeito na forma** (linhas/colunas) e exibe **amostra** (primeiras 10 linhas).\n",
    "\n",
    "**Por quê:** validar que títulos/legendas foram removidos, parágrafos curtos foram fundidos e que a estrutura (`doc`, `dt`, `pid`, `texto`, `n_palavras`) permaneceu correta.\n",
    "\n",
    "**Saída:** `df_paragrafos_limpos` (dataframe limpo)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a51c7a4",
   "metadata": {},
   "source": [
    "## Instalação\n",
    "\n",
    "O que faz: instala libs para carregar modelos (transformers), datasets (datasets), métricas (sklearn) e treino (torch/accelerate)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f571019e",
   "metadata": {
    "vscode": {
     "languageId": "bat"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in /usr/local/python/3.12.1/lib/python3.12/site-packages (4.57.1)\n",
      "Requirement already satisfied: datasets in /usr/local/python/3.12.1/lib/python3.12/site-packages (4.2.0)\n",
      "Requirement already satisfied: scikit-learn in /usr/local/python/3.12.1/lib/python3.12/site-packages (1.7.2)\n",
      "Requirement already satisfied: accelerate in /usr/local/python/3.12.1/lib/python3.12/site-packages (1.11.0)\n",
      "Requirement already satisfied: torch in /usr/local/python/3.12.1/lib/python3.12/site-packages (2.9.0)\n",
      "Requirement already satisfied: filelock in /home/codespace/.local/lib/python3.12/site-packages (from transformers) (3.13.1)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.34.0 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from transformers) (0.35.3)\n",
      "Requirement already satisfied: numpy>=1.17 in /home/codespace/.local/lib/python3.12/site-packages (from transformers) (2.3.1)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/codespace/.local/lib/python3.12/site-packages (from transformers) (25.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /home/codespace/.local/lib/python3.12/site-packages (from transformers) (6.0.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from transformers) (2025.10.23)\n",
      "Requirement already satisfied: requests in /home/codespace/.local/lib/python3.12/site-packages (from transformers) (2.32.4)\n",
      "Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from transformers) (0.22.1)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from transformers) (0.6.2)\n",
      "Requirement already satisfied: tqdm>=4.27 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from transformers) (4.67.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /home/codespace/.local/lib/python3.12/site-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (2024.6.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /home/codespace/.local/lib/python3.12/site-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (4.14.1)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (1.1.10)\n",
      "Requirement already satisfied: pyarrow>=21.0.0 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from datasets) (21.0.0)\n",
      "Requirement already satisfied: dill<0.4.1,>=0.3.0 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from datasets) (0.4.0)\n",
      "Requirement already satisfied: pandas in /home/codespace/.local/lib/python3.12/site-packages (from datasets) (2.3.1)\n",
      "Requirement already satisfied: httpx<1.0.0 in /home/codespace/.local/lib/python3.12/site-packages (from datasets) (0.28.1)\n",
      "Requirement already satisfied: xxhash in /usr/local/python/3.12.1/lib/python3.12/site-packages (from datasets) (3.6.0)\n",
      "Requirement already satisfied: multiprocess<0.70.17 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from datasets) (0.70.16)\n",
      "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from fsspec[http]<=2025.9.0,>=2023.1.0->datasets) (3.13.1)\n",
      "Requirement already satisfied: anyio in /home/codespace/.local/lib/python3.12/site-packages (from httpx<1.0.0->datasets) (4.9.0)\n",
      "Requirement already satisfied: certifi in /home/codespace/.local/lib/python3.12/site-packages (from httpx<1.0.0->datasets) (2025.7.9)\n",
      "Requirement already satisfied: httpcore==1.* in /home/codespace/.local/lib/python3.12/site-packages (from httpx<1.0.0->datasets) (1.0.9)\n",
      "Requirement already satisfied: idna in /home/codespace/.local/lib/python3.12/site-packages (from httpx<1.0.0->datasets) (3.10)\n",
      "Requirement already satisfied: h11>=0.16 in /home/codespace/.local/lib/python3.12/site-packages (from httpcore==1.*->httpx<1.0.0->datasets) (0.16.0)\n",
      "Requirement already satisfied: scipy>=1.8.0 in /home/codespace/.local/lib/python3.12/site-packages (from scikit-learn) (1.16.0)\n",
      "Requirement already satisfied: joblib>=1.2.0 in /home/codespace/.local/lib/python3.12/site-packages (from scikit-learn) (1.5.1)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /home/codespace/.local/lib/python3.12/site-packages (from scikit-learn) (3.6.0)\n",
      "Requirement already satisfied: psutil in /home/codespace/.local/lib/python3.12/site-packages (from accelerate) (7.0.0)\n",
      "Requirement already satisfied: setuptools in /home/codespace/.local/lib/python3.12/site-packages (from torch) (80.9.0)\n",
      "Requirement already satisfied: sympy>=1.13.3 in /home/codespace/.local/lib/python3.12/site-packages (from torch) (1.13.3)\n",
      "Requirement already satisfied: networkx>=2.5.1 in /home/codespace/.local/lib/python3.12/site-packages (from torch) (3.3)\n",
      "Requirement already satisfied: jinja2 in /home/codespace/.local/lib/python3.12/site-packages (from torch) (3.1.6)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.8.93 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from torch) (12.8.93)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.8.90 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from torch) (12.8.90)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.8.90 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from torch) (12.8.90)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from torch) (9.10.2.21)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.8.4.1 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from torch) (12.8.4.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.3.3.83 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from torch) (11.3.3.83)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.9.90 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from torch) (10.3.9.90)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.7.3.90 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from torch) (11.7.3.90)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.5.8.93 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from torch) (12.5.8.93)\n",
      "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from torch) (0.7.1)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.27.5 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from torch) (2.27.5)\n",
      "Requirement already satisfied: nvidia-nvshmem-cu12==3.3.20 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from torch) (3.3.20)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.8.90 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from torch) (12.8.90)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.8.93 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from torch) (12.8.93)\n",
      "Requirement already satisfied: nvidia-cufile-cu12==1.13.1.3 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from torch) (1.13.1.3)\n",
      "Requirement already satisfied: triton==3.5.0 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from torch) (3.5.0)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.9.0,>=2023.1.0->datasets) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.9.0,>=2023.1.0->datasets) (1.4.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /home/codespace/.local/lib/python3.12/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.9.0,>=2023.1.0->datasets) (25.3.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.9.0,>=2023.1.0->datasets) (1.8.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.9.0,>=2023.1.0->datasets) (6.7.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.9.0,>=2023.1.0->datasets) (0.4.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.9.0,>=2023.1.0->datasets) (1.22.0)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /home/codespace/.local/lib/python3.12/site-packages (from requests->transformers) (3.4.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/codespace/.local/lib/python3.12/site-packages (from requests->transformers) (2.5.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /home/codespace/.local/lib/python3.12/site-packages (from sympy>=1.13.3->torch) (1.3.0)\n",
      "Requirement already satisfied: sniffio>=1.1 in /home/codespace/.local/lib/python3.12/site-packages (from anyio->httpx<1.0.0->datasets) (1.3.1)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/codespace/.local/lib/python3.12/site-packages (from jinja2->torch) (3.0.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /home/codespace/.local/lib/python3.12/site-packages (from pandas->datasets) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /home/codespace/.local/lib/python3.12/site-packages (from pandas->datasets) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /home/codespace/.local/lib/python3.12/site-packages (from pandas->datasets) (2025.2)\n",
      "Requirement already satisfied: six>=1.5 in /home/codespace/.local/lib/python3.12/site-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.1.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython -m pip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install -U transformers datasets scikit-learn accelerate torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6a6daaab",
   "metadata": {
    "vscode": {
     "languageId": "bat"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Criei 'out/dataset_para_rotular_risco.csv'. Preencha 'label' com: ['otimista_risco', 'neutro_risco', 'pessimista_risco']\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "# 1) garantir a base de parágrafos\n",
    "if 'df_paragrafos_limpos' not in globals():\n",
    "    if Path(\"paragrafos.csv\").exists():\n",
    "        df_paragrafos_limpos = pd.read_csv(\"paragrafos.csv\")\n",
    "    else:\n",
    "        raise RuntimeError(\"Crie 'df_paragrafos_limpos' ou exporte 'paragrafos.csv' antes.\")\n",
    "\n",
    "# 2) esquema de rótulos de risco\n",
    "LABELS_RISCO = [\"otimista_risco\",\"neutro_risco\",\"pessimista_risco\"]\n",
    "\n",
    "# 3) amostra inicial p/ rotular (ex.: até 900 linhas)\n",
    "amostra = df_paragrafos_limpos.sample(n=min(900, len(df_paragrafos_limpos)), random_state=42).copy()\n",
    "amostra[\"id\"] = amostra.apply(lambda r: f\"{r['doc']}|{r['dt']}|{r['pid']}\", axis=1)\n",
    "\n",
    "rotular = amostra[[\"id\",\"doc\",\"dt\",\"pid\",\"texto\"]].copy()\n",
    "rotular[\"label\"] = \"\"  # você preencherá com um dos LABELS_RISCO\n",
    "\n",
    "Path(\"out\").mkdir(parents=True, exist_ok=True)\n",
    "rotular.to_csv(\"out/dataset_para_rotular_risco.csv\", index=False)\n",
    "print(\"Criei 'out/dataset_para_rotular_risco.csv'. Preencha 'label' com:\", LABELS_RISCO)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1536e77f",
   "metadata": {
    "vscode": {
     "languageId": "bat"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>doc</th>\n",
       "      <th>dt</th>\n",
       "      <th>pid</th>\n",
       "      <th>texto</th>\n",
       "      <th>label</th>\n",
       "      <th>score_heur</th>\n",
       "      <th>sugestao</th>\n",
       "      <th>conf</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>777</th>\n",
       "      <td>202210|2022-10-01 00:00:00|20</td>\n",
       "      <td>202210</td>\n",
       "      <td>2022-10-01</td>\n",
       "      <td>20</td>\n",
       "      <td>As séries estão publicadas no Sistema Gerencia...</td>\n",
       "      <td>neutro_risco</td>\n",
       "      <td>0.0</td>\n",
       "      <td>neutro_risco</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>202210|2022-10-01 00:00:00|17</td>\n",
       "      <td>202210</td>\n",
       "      <td>2022-10-01</td>\n",
       "      <td>17</td>\n",
       "      <td>• crédito ampliado ao setor não financeiro, no...</td>\n",
       "      <td>neutro_risco</td>\n",
       "      <td>0.0</td>\n",
       "      <td>neutro_risco</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>202501|2025-01-01 00:00:00|15</td>\n",
       "      <td>202501</td>\n",
       "      <td>2025-01-01</td>\n",
       "      <td>15</td>\n",
       "      <td>Entre os fluxos mensais dos fatores condiciona...</td>\n",
       "      <td>neutro_risco</td>\n",
       "      <td>0.0</td>\n",
       "      <td>neutro_risco</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>202401|2024-01-01 00:00:00|16</td>\n",
       "      <td>202401</td>\n",
       "      <td>2024-01-01</td>\n",
       "      <td>16</td>\n",
       "      <td>Entre os fluxos mensais dos fatores condiciona...</td>\n",
       "      <td>neutro_risco</td>\n",
       "      <td>0.0</td>\n",
       "      <td>neutro_risco</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>202507|2025-07-01 00:00:00|11</td>\n",
       "      <td>202507</td>\n",
       "      <td>2025-07-01</td>\n",
       "      <td>11</td>\n",
       "      <td>No crédito livre , a taxa média de juros situo...</td>\n",
       "      <td>neutro_risco</td>\n",
       "      <td>1.0</td>\n",
       "      <td>neutro_risco</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>594</th>\n",
       "      <td>202307|2023-07-01 00:00:00|5</td>\n",
       "      <td>202307</td>\n",
       "      <td>2023-07-01</td>\n",
       "      <td>5</td>\n",
       "      <td>As concessões nominais de crédito totalizaram ...</td>\n",
       "      <td>pessimista_risco</td>\n",
       "      <td>5.0</td>\n",
       "      <td>pessimista_risco</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>539</th>\n",
       "      <td>202412|2024-12-01 00:00:00|8</td>\n",
       "      <td>202412</td>\n",
       "      <td>2024-12-01</td>\n",
       "      <td>8</td>\n",
       "      <td>A taxa média de juros das concessões atingiu 2...</td>\n",
       "      <td>pessimista_risco</td>\n",
       "      <td>4.0</td>\n",
       "      <td>pessimista_risco</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>571</th>\n",
       "      <td>202412|2024-12-01 00:00:00|4</td>\n",
       "      <td>202412</td>\n",
       "      <td>2024-12-01</td>\n",
       "      <td>4</td>\n",
       "      <td>O estoque das operações de crédito do SFN aume...</td>\n",
       "      <td>pessimista_risco</td>\n",
       "      <td>5.0</td>\n",
       "      <td>pessimista_risco</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>202307|2023-07-01 00:00:00|13</td>\n",
       "      <td>202307</td>\n",
       "      <td>2023-07-01</td>\n",
       "      <td>13</td>\n",
       "      <td>O M2 cresceu 1,7% no mês, com saldo total de R...</td>\n",
       "      <td>pessimista_risco</td>\n",
       "      <td>4.0</td>\n",
       "      <td>pessimista_risco</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>202310|2023-10-01 00:00:00|3</td>\n",
       "      <td>202310</td>\n",
       "      <td>2023-10-01</td>\n",
       "      <td>3</td>\n",
       "      <td>O crédito com recursos direcionado s somou R$2...</td>\n",
       "      <td>pessimista_risco</td>\n",
       "      <td>4.0</td>\n",
       "      <td>pessimista_risco</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>793 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                id     doc          dt  pid  \\\n",
       "777  202210|2022-10-01 00:00:00|20  202210  2022-10-01   20   \n",
       "24   202210|2022-10-01 00:00:00|17  202210  2022-10-01   17   \n",
       "23   202501|2025-01-01 00:00:00|15  202501  2025-01-01   15   \n",
       "22   202401|2024-01-01 00:00:00|16  202401  2024-01-01   16   \n",
       "21   202507|2025-07-01 00:00:00|11  202507  2025-07-01   11   \n",
       "..                             ...     ...         ...  ...   \n",
       "594   202307|2023-07-01 00:00:00|5  202307  2023-07-01    5   \n",
       "539   202412|2024-12-01 00:00:00|8  202412  2024-12-01    8   \n",
       "571   202412|2024-12-01 00:00:00|4  202412  2024-12-01    4   \n",
       "92   202307|2023-07-01 00:00:00|13  202307  2023-07-01   13   \n",
       "44    202310|2023-10-01 00:00:00|3  202310  2023-10-01    3   \n",
       "\n",
       "                                                 texto             label  \\\n",
       "777  As séries estão publicadas no Sistema Gerencia...      neutro_risco   \n",
       "24   • crédito ampliado ao setor não financeiro, no...      neutro_risco   \n",
       "23   Entre os fluxos mensais dos fatores condiciona...      neutro_risco   \n",
       "22   Entre os fluxos mensais dos fatores condiciona...      neutro_risco   \n",
       "21   No crédito livre , a taxa média de juros situo...      neutro_risco   \n",
       "..                                                 ...               ...   \n",
       "594  As concessões nominais de crédito totalizaram ...  pessimista_risco   \n",
       "539  A taxa média de juros das concessões atingiu 2...  pessimista_risco   \n",
       "571  O estoque das operações de crédito do SFN aume...  pessimista_risco   \n",
       "92   O M2 cresceu 1,7% no mês, com saldo total de R...  pessimista_risco   \n",
       "44   O crédito com recursos direcionado s somou R$2...  pessimista_risco   \n",
       "\n",
       "     score_heur          sugestao  conf  \n",
       "777         0.0      neutro_risco   0.5  \n",
       "24          0.0      neutro_risco   0.5  \n",
       "23          0.0      neutro_risco   0.5  \n",
       "22          0.0      neutro_risco   0.5  \n",
       "21          1.0      neutro_risco   0.5  \n",
       "..          ...               ...   ...  \n",
       "594         5.0  pessimista_risco   1.0  \n",
       "539         4.0  pessimista_risco   1.0  \n",
       "571         5.0  pessimista_risco   1.0  \n",
       "92          4.0  pessimista_risco   1.0  \n",
       "44          4.0  pessimista_risco   1.0  \n",
       "\n",
       "[793 rows x 9 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "path_in = Path(\"out/dataset_para_rotular_risco.csv\")\n",
    "if not path_in.exists():\n",
    "    raise RuntimeError(\"Execute o passo 1 primeiro (gera dataset_para_rotular_risco.csv).\")\n",
    "\n",
    "df = pd.read_csv(path_in)\n",
    "\n",
    "# NEGATIVO — inadimplência/risco em alta, perdas, stress, rebaixamentos\n",
    "neg_kw = r\"\"\"(?i)\\b(\n",
    "    inadimpl(?:e|ê)n(?:c(?:ia|ial)?|te|tes)?|\n",
    "    calot(?:e|eiros?)|\n",
    "    default(?:s)?|\n",
    "    atras(?:o|os|ou|ar|ados?)|\n",
    "    provis(?:[õo]es?|[ãa]o|ionamentos?)(?: adicionais?)?|\n",
    "    npl(?:s)?|\n",
    "    perd(?:a|as)(?: esperad[as]?| incorrid[as]?)?|\n",
    "    deterior(?:a(?:ç(?:[ãa]o|ões))?|ou|ar)|\n",
    "    risco(?:s)?|\n",
    "    incertez(?:a|as)|\n",
    "    (?:stress|estresse)|\n",
    "    liquidez (?:restrit[ao]s?|escass[ao]s?|apertad[ao]s?|curta)|\n",
    "    pior(?:a(?:ç(?:[ãa]o)?)?|ou)|\n",
    "    eleva(?:ç(?:[ãa]o|ões)|c(?:a|ã)o|ou)|subid(?:a|as)|subiu|alt(?:a|as)|aument(?:o|os|ou|ar)|\n",
    "    rebaix(?:amento|ou)s?|downgrade(?:s)?|\n",
    "    venciment(?:o )?antecipad(?:o|os)|\n",
    "    (?:quebr(?:a|as)|viola(?:ç(?:[ãa]o)?)|violou) de covenant|covenant breach|\n",
    "    impairment(?:s)?|\n",
    "    baixa(?:s)? a preju(?:í|i)zo|write-?off(?:s)?|\n",
    "    perda por redu(?:ç(?:[ãa]o)) ao valor recuper[aá]vel|\n",
    "    recupera(?:ç(?:[ãa]o)) judicial|fal[êe]ncia|insolv[êe]ncia|\n",
    "    execu(?:ç(?:[ãa]o)) de garantias|\n",
    "    inadimpl(?:e|ê)ncia(?: >? ?90 ?d(?:ias)?)?\n",
    ")\\b\"\"\"\n",
    "\n",
    "# POSITIVO — melhora de crédito, reduções de risco/provisões, upgrades, liquidez forte\n",
    "pos_kw = r\"\"\"(?i)\\b(\n",
    "    melhor(?:a|ou|ar|ias?)|\n",
    "    redu(?:ç(?:[ãa]o|ões)|ziu|zir)|\n",
    "    queda(?:s)?|caiu|ca(?:i|í)da(?:s)?|\n",
    "    diminui(?:u|ç(?:[ãa]o|ões))|\n",
    "    est[áa]vel(?:es)?|sob controle|controlad(?:o|a|os|as)|\n",
    "    robust(?:o|a|ez|os|as)|\n",
    "    solv(?:ê|e)nc(?:ia|e)|\n",
    "    cobertura (?:maior|superior)|\n",
    "    provis(?:[õo]es?) (?:menores|liberadas)|revers(?:[ãa]o) de provis(?:[õo]es?)|write-?back(?:s)?|\n",
    "    npl(?:s)? (?:menor(?:es)?|em queda)|\n",
    "    inadimpl(?:e|ê)n(?:c(?:ia)?)? (?:menor|em queda|controlad[ao]s?)|\n",
    "    recupera(?:ç(?:[ãa]o)) de cr[eé]dito(?:s)?|cr[eé]ditos recuperados|\n",
    "    refor(?:ç(?:o|os)) de garantias|colateral adicional|\n",
    "    desalavanc(?:e|a)gem|alavancagem menor|\n",
    "    upgrade(?:s)?|eleva(?:ç(?:[ãa]o)) de rating|perspectiva positiva|\n",
    "    liquidez (?:s[óo]lida|folgada|confort[aá]vel|robusta)|\n",
    "    custo do risco (?:menor|em queda)|\n",
    "    llp(?:s)? (?:menor(?:es)?)|provis(?:[õo]es?) sobre cr[eé]ditos (?:menores)\n",
    ")\\b\"\"\"\n",
    "\n",
    "\n",
    "def score_risco(txt: str) -> float:\n",
    "    t = txt.lower()\n",
    "    s = 0\n",
    "    s += 1.0 * len(re.findall(neg_kw, t))\n",
    "    s -= 1.0 * len(re.findall(pos_kw, t))\n",
    "    return float(s)\n",
    "\n",
    "df[\"score_heur\"] = df[\"texto\"].astype(str).map(score_risco)\n",
    "\n",
    "# Converter score → sugestão e \"confiança\"\n",
    "def sug_conf(s: float):\n",
    "    if s >= 2:   return \"pessimista_risco\", min(1.0, 0.6 + 0.1*s)  # mais pessimista, confiança ↑\n",
    "    if s <= -2:  return \"otimista_risco\",  min(1.0, 0.6 + 0.1*(-s))\n",
    "    if -1 <= s <= 1: return \"neutro_risco\", 0.50\n",
    "    return (\"pessimista_risco\" if s>0 else \"otimista_risco\"), 0.55\n",
    "\n",
    "out = df.copy()\n",
    "out[\"sugestao\"], out[\"conf\"] = zip(*out[\"score_heur\"].map(sug_conf))\n",
    "\n",
    "# Pré-preenche 'label' com a sugestão (você pode filtrar por conf e revisar)\n",
    "out[\"label\"] = out[\"sugestao\"]\n",
    "\n",
    "# Ordenar para revisão: casos de menor confiança primeiro\n",
    "out_rev = out.sort_values(\"conf\", ascending=True)\n",
    "out_rev\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "60be279b",
   "metadata": {
    "vscode": {
     "languageId": "bat"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>doc</th>\n",
       "      <th>dt</th>\n",
       "      <th>pid</th>\n",
       "      <th>texto</th>\n",
       "      <th>label</th>\n",
       "      <th>score_heur</th>\n",
       "      <th>sugestao</th>\n",
       "      <th>conf</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>777</th>\n",
       "      <td>202210|2022-10-01 00:00:00|20</td>\n",
       "      <td>202210</td>\n",
       "      <td>2022-10-01</td>\n",
       "      <td>20</td>\n",
       "      <td>As séries estão publicadas no Sistema Gerencia...</td>\n",
       "      <td>neutro_risco</td>\n",
       "      <td>0.0</td>\n",
       "      <td>neutro_risco</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>202210|2022-10-01 00:00:00|17</td>\n",
       "      <td>202210</td>\n",
       "      <td>2022-10-01</td>\n",
       "      <td>17</td>\n",
       "      <td>• crédito ampliado ao setor não financeiro, no...</td>\n",
       "      <td>neutro_risco</td>\n",
       "      <td>0.0</td>\n",
       "      <td>neutro_risco</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>202501|2025-01-01 00:00:00|15</td>\n",
       "      <td>202501</td>\n",
       "      <td>2025-01-01</td>\n",
       "      <td>15</td>\n",
       "      <td>Entre os fluxos mensais dos fatores condiciona...</td>\n",
       "      <td>neutro_risco</td>\n",
       "      <td>0.0</td>\n",
       "      <td>neutro_risco</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>202401|2024-01-01 00:00:00|16</td>\n",
       "      <td>202401</td>\n",
       "      <td>2024-01-01</td>\n",
       "      <td>16</td>\n",
       "      <td>Entre os fluxos mensais dos fatores condiciona...</td>\n",
       "      <td>neutro_risco</td>\n",
       "      <td>0.0</td>\n",
       "      <td>neutro_risco</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>202507|2025-07-01 00:00:00|11</td>\n",
       "      <td>202507</td>\n",
       "      <td>2025-07-01</td>\n",
       "      <td>11</td>\n",
       "      <td>No crédito livre , a taxa média de juros situo...</td>\n",
       "      <td>neutro_risco</td>\n",
       "      <td>1.0</td>\n",
       "      <td>neutro_risco</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>594</th>\n",
       "      <td>202307|2023-07-01 00:00:00|5</td>\n",
       "      <td>202307</td>\n",
       "      <td>2023-07-01</td>\n",
       "      <td>5</td>\n",
       "      <td>As concessões nominais de crédito totalizaram ...</td>\n",
       "      <td>pessimista_risco</td>\n",
       "      <td>5.0</td>\n",
       "      <td>pessimista_risco</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>539</th>\n",
       "      <td>202412|2024-12-01 00:00:00|8</td>\n",
       "      <td>202412</td>\n",
       "      <td>2024-12-01</td>\n",
       "      <td>8</td>\n",
       "      <td>A taxa média de juros das concessões atingiu 2...</td>\n",
       "      <td>pessimista_risco</td>\n",
       "      <td>4.0</td>\n",
       "      <td>pessimista_risco</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>571</th>\n",
       "      <td>202412|2024-12-01 00:00:00|4</td>\n",
       "      <td>202412</td>\n",
       "      <td>2024-12-01</td>\n",
       "      <td>4</td>\n",
       "      <td>O estoque das operações de crédito do SFN aume...</td>\n",
       "      <td>pessimista_risco</td>\n",
       "      <td>5.0</td>\n",
       "      <td>pessimista_risco</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>202307|2023-07-01 00:00:00|13</td>\n",
       "      <td>202307</td>\n",
       "      <td>2023-07-01</td>\n",
       "      <td>13</td>\n",
       "      <td>O M2 cresceu 1,7% no mês, com saldo total de R...</td>\n",
       "      <td>pessimista_risco</td>\n",
       "      <td>4.0</td>\n",
       "      <td>pessimista_risco</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>202310|2023-10-01 00:00:00|3</td>\n",
       "      <td>202310</td>\n",
       "      <td>2023-10-01</td>\n",
       "      <td>3</td>\n",
       "      <td>O crédito com recursos direcionado s somou R$2...</td>\n",
       "      <td>pessimista_risco</td>\n",
       "      <td>4.0</td>\n",
       "      <td>pessimista_risco</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>793 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                id     doc          dt  pid  \\\n",
       "777  202210|2022-10-01 00:00:00|20  202210  2022-10-01   20   \n",
       "24   202210|2022-10-01 00:00:00|17  202210  2022-10-01   17   \n",
       "23   202501|2025-01-01 00:00:00|15  202501  2025-01-01   15   \n",
       "22   202401|2024-01-01 00:00:00|16  202401  2024-01-01   16   \n",
       "21   202507|2025-07-01 00:00:00|11  202507  2025-07-01   11   \n",
       "..                             ...     ...         ...  ...   \n",
       "594   202307|2023-07-01 00:00:00|5  202307  2023-07-01    5   \n",
       "539   202412|2024-12-01 00:00:00|8  202412  2024-12-01    8   \n",
       "571   202412|2024-12-01 00:00:00|4  202412  2024-12-01    4   \n",
       "92   202307|2023-07-01 00:00:00|13  202307  2023-07-01   13   \n",
       "44    202310|2023-10-01 00:00:00|3  202310  2023-10-01    3   \n",
       "\n",
       "                                                 texto             label  \\\n",
       "777  As séries estão publicadas no Sistema Gerencia...      neutro_risco   \n",
       "24   • crédito ampliado ao setor não financeiro, no...      neutro_risco   \n",
       "23   Entre os fluxos mensais dos fatores condiciona...      neutro_risco   \n",
       "22   Entre os fluxos mensais dos fatores condiciona...      neutro_risco   \n",
       "21   No crédito livre , a taxa média de juros situo...      neutro_risco   \n",
       "..                                                 ...               ...   \n",
       "594  As concessões nominais de crédito totalizaram ...  pessimista_risco   \n",
       "539  A taxa média de juros das concessões atingiu 2...  pessimista_risco   \n",
       "571  O estoque das operações de crédito do SFN aume...  pessimista_risco   \n",
       "92   O M2 cresceu 1,7% no mês, com saldo total de R...  pessimista_risco   \n",
       "44   O crédito com recursos direcionado s somou R$2...  pessimista_risco   \n",
       "\n",
       "     score_heur          sugestao  conf  \n",
       "777         0.0      neutro_risco   0.5  \n",
       "24          0.0      neutro_risco   0.5  \n",
       "23          0.0      neutro_risco   0.5  \n",
       "22          0.0      neutro_risco   0.5  \n",
       "21          1.0      neutro_risco   0.5  \n",
       "..          ...               ...   ...  \n",
       "594         5.0  pessimista_risco   1.0  \n",
       "539         4.0  pessimista_risco   1.0  \n",
       "571         5.0  pessimista_risco   1.0  \n",
       "92          4.0  pessimista_risco   1.0  \n",
       "44          4.0  pessimista_risco   1.0  \n",
       "\n",
       "[793 rows x 9 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "LABELS_RISCO = [\"otimista_risco\",\"neutro_risco\",\"pessimista_risco\"]\n",
    "\n",
    "df_risk = out_rev\n",
    "df_risk[\"label\"] = df_risk[\"label\"].str.strip().str.lower()\n",
    "df_risk = df_risk[df_risk[\"label\"].isin(LABELS_RISCO)].copy()\n",
    "df_risk\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96d3bc5d",
   "metadata": {},
   "source": [
    "# 2) DeB3RTA\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b73bff49",
   "metadata": {
    "vscode": {
     "languageId": "bat"
    }
   },
   "outputs": [],
   "source": [
    "from transformers import AutoModelForMaskedLM, AutoTokenizer\n",
    "\n",
    "# Load model and tokenizer\n",
    "model = AutoModelForMaskedLM.from_pretrained(\"higopires/DeB3RTa-[base/small]\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"higopires/DeB3RTa-[base/small]\")\n",
    "\n",
    "# Example usage\n",
    "text = \"O mercado financeiro brasileiro apresentou [MASK] no último trimestre.\"\n",
    "inputs = tokenizer(text, return_tensors=\"pt\")\n",
    "outputs = model(**inputs)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dc11fe3",
   "metadata": {},
   "source": [
    "# 3) FinBERT-PT-BR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e95e6088",
   "metadata": {
    "vscode": {
     "languageId": "bat"
    }
   },
   "outputs": [],
   "source": [
    "from transformers import (\n",
    "    AutoTokenizer, \n",
    "    BertForSequenceClassification,\n",
    "    pipeline,\n",
    ")\n",
    "\n",
    "finbert_pt_br_tokenizer = AutoTokenizer.from_pretrained(\"lucas-leme/FinBERT-PT-BR\")\n",
    "finbert_pt_br_model = BertForSequenceClassification.from_pretrained(\"lucas-leme/FinBERT-PT-BR\")\n",
    "\n",
    "finbert_pt_br_pipeline = pipeline(task='text-classification', model=finbert_pt_br_model, tokenizer=finbert_pt_br_tokenizer)\n",
    "finbert_pt_br_pipeline(['Hoje a bolsa caiu', 'Hoje a bolsa subiu'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
